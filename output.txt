Microsoft Windows [Version 10.0.26200.7623]
(c) Microsoft Corporation. All rights reserved.

C:\Users\salim>cd course-assistant-rag

C:\Users\salim\course-assistant-rag>venu\scripts\activate
The system cannot find the path specified.

C:\Users\salim\course-assistant-rag>venv\scripts\activate

(venv) C:\Users\salim\course-assistant-rag>python main.py
Initializing Agentic RAG System...
============================================================
Loading tools...
Initializing embeddings model...
Loading existing vector store from chroma_db...
Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given
Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given
Loaded 1547 documents from vector store.
âœ“ All tools loaded successfully
Initializing Llama 3.1 model...
âœ“ Model initialized with tool capabilities
Building LangGraph workflow...
âœ“ LangGraph workflow compiled successfully
============================================================

System ready! ðŸš€

Agentic RAG System - Interactive Mode
Ask me about:
  â€¢ Course materials (e.g., 'What is PageRank?')
  â€¢ Weather (e.g., 'What's the weather in Haifa today?')
  â€¢ Your schedule (e.g., 'When is my next exam?')
  â€¢ Holidays (e.g., 'When is the next holiday in Israel?')

Type 'quit' to exit

YOU: What is TF-IDF?

============================================================
USER: What is TF-IDF?
============================================================

ðŸ”§ Calling tool: search_course_materials
   Arguments: {'query': 'TF-IDF'}

Searching for: 'TF-IDF'
Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given
Found 5 relevant chunks.
   Result preview:   ==================================================  ðŸ“„ Chunk 1: Information Retrieval - Word Similarity  - WordNet - Word Vectors Development: Moshe Friedman C...

============================================================
ASSISTANT: TF-IDF (Term Frequency-Inverse Document Frequency) is a technique used in Information Retrieval to calculate the importance of words in a document. It takes into account both the frequency of a word within a document (term frequency) and its rarity across all documents in the corpus (inverse document frequency).

The goal of TF-IDF is to assign higher weights to words that are highly relevant to the document, while downplaying those that are common or irrelevant.

For example, if we have two documents:

Doc 1: "The quick brown fox jumps over the lazy dog."
Doc 2: "The sun was shining brightly in the clear blue sky."

In this case, the word "the" would have a high term frequency in both documents, but its inverse document frequency would be low because it's a common word. On the other hand, the word "fox" would have a high term frequency in Doc 1 and a low inverse document frequency because it's rare across all documents.

By combining these two factors, TF-IDF can help us identify the most important words in a document and improve the accuracy of search results.
============================================================

YOU: What is the weather in Haifa?

============================================================
USER: What is the weather in Haifa?
============================================================

ðŸ”§ Calling tool: get_weather
   Arguments: {'location': 'Haifa, Israel'}
   Result preview: Current weather in Haifa, Israel: - Temperature: 21.1Â°C - Wind: 10.9 km/h - Weather code: 3 - Time: 2026-02-02T01:00...

============================================================
ASSISTANT: **Weather**
Current weather in Haifa, Israel:
- Temperature: 21.1Â°C
- Wind: 10.9 km/h
- Weather code: 3
- Time: 2026-02-02T01:00
============================================================

YOU: What is the next holiday?

============================================================
USER: What is the next holiday?
============================================================

ðŸ”§ Calling tool: get_next_holiday
   Arguments: {'country_code': 'IL'}

Finding next holiday in IL after 2026-02-02...
   Result preview: Next holiday in IL: 2026-03-02 â€” Erev Purim....

============================================================
ASSISTANT: **Holidays**
Next holiday in IL: 2026-03-02 â€” Erev Purim.
============================================================

YOU: When is my next exam?

============================================================
USER: When is my next exam?
============================================================

ðŸ”§ Calling tool: check_calendar
   Arguments: {'query': 'next exam'}
   Result preview: {"found": true, "title": "Machine Learning Exam", "date": "2026-02-10", "time": "09:00", "type": "exam"}...

============================================================
ASSISTANT: **Schedule / Exams**
Next exam: Machine Learning Exam
Date: 2026-02-10 09:00
============================================================

YOU: What is Link Analysis and what is the weather in Haifa Israel?

============================================================
USER: What is Link Analysis and what is the weather in Haifa Israel?
============================================================

ðŸ”§ Calling tool: search_course_materials
   Arguments: {'query': 'Link Analysis'}

Searching for: 'Link Analysis'
Found 5 relevant chunks.
   Result preview:   ==================================================  ðŸ“„ Chunk 1: Introduction to Information Retrieval Probabilistic Information Retrieval Christopher Manning a...

ðŸ”§ Calling tool: get_weather
   Arguments: {'location': 'Haifa, Israel'}
   Result preview: Current weather in Haifa, Israel: - Temperature: 21.1Â°C - Wind: 10.9 km/h - Weather code: 3 - Time: 2026-02-02T01:00...

============================================================
ASSISTANT: **Weather**
Current weather in Haifa, Israel:
- Temperature: 21.1Â°C
- Wind: 10.9 km/h
- Weather code: 3
- Time: 2026-02-02T01:00

**Course explanation**
**Main explanation**

1. Link Analysis is a technique used in Information Retrieval to analyze the relationships between web pages or documents by examining the links that connect them.
2. It involves analyzing the structure of the web graph, including the number and quality of incoming and outgoing links, to infer the importance and relevance of each page.
3. This analysis can help identify authoritative sources, detect spam or low-quality content, and improve search engine rankings.

**Example/Formula**

No specific formula is provided in the evidence for Link Analysis, but it often involves calculating metrics such as PageRank (PR) using the equation: PR(A) = (1-d) + d \* (PR(B)/C(B,A)), where A is a web page, B is a linked page, C(B,A) is the number of links from B to A, and d is a damping factor.

**Practical connection**

Link Analysis has practical applications in search engine optimization (SEO), web spam detection, and content recommendation systems.

**Evidence (retrieved chunks)**
==================================================

ðŸ“„ Chunk 1:
Introduction to
Information Retrieval
Probabilistic Information Retrieval
Christopher Manning and Pandu Nayak

ðŸ“„ Chunk 2:
Classifying: "Money Grade"
Result: SPAM (0.059 > 0.013)
Score for Normal (N)
P(N) * P(Money|N) * P(Grade|N)
= 0.013
Score for Spam (S)
P(S) * P(Money|S) * P(Grade|S)
= 0.059
= 0.625 * 0.07 * 0.30 = 0.375 * 0.63 * 0.25

ðŸ“„ Chunk 3:
A Small Example â€“ 4
 0.22 -0.11  0.29 -0.41 -0.11 -0.34  0.52 -0.06 -0.41
 0.20 -0.07  0.14 -0.55  0.28  0.50 -0.07 -0.01 -0.11
 0.24  0.04 -0.16 -0.59 -0.11 -0.25 -0.30  0.06  0.49
 0.40  0.06 -0.34  0.10  0.33  0.38  0.00  0.00  0.01
 0.64 -0.17  0.36  0.33 -0.16 -0.21 -0.17  0.03  0.27
 0.27  0.11 -0.43  0.07  0.08 -0.17  0.28 -0.02 -0.05
 0.27 0.11 -0.43  0.07  0.08 -0.17  0.28 -0.02 -0.05
 0.30 -0.14  0.33  0.19  0.11  0.27  0.03 -0.02 -0.17
 0.21  0.27 -0.18 -0.03 -0.54  0.08 -0.47 -0.04 -0.58
 0.01  0.49  0.23  0.03  0.59 -0.39 -0.29  0.25 -0.23
 0.04  0.62  0.22  0.00 -0.07  0.11  0.16 -0.68  0.23
 0.03  0.45  0.14 -0.01 -0.30  0.28  0.34  0.68  0.18
â€¢ {U} =

ðŸ“„ Chunk 4:
Introduction to
Information Retrieval
Evaluation
Chris Manning and Pandu Nayak
CS276 â€“ Information Retrieval and Web Search

ðŸ“„ Chunk 5:
Information Retrieval
â€¢ Introduction
â€¢ Text and Language
Development:
Moshe Friedman
Credits:
Yoav Goldberg, Ido Dagan, Reut Tsarfaty , Moshe Koppel, Wei Song,
David Bamman, Ed Grefenstette, Chris Manning, Tsvi Kuflik,
Hinrich SchÃ¼tze, Christina Lioma and more
============================================================

YOU: Will I need a jacket for today?

============================================================
USER: Will I need a jacket for today?
============================================================

ðŸ”§ Calling tool: get_weather
   Arguments: {'location': 'Haifa, Israel', 'on_date': '2026-02-02'}
   Result preview: Forecast for Haifa, Israel on 2026-02-02: - Temperature: 16.8Â°C to 22.3Â°C - Max precipitation probability: 20% - Max wind: 20.7 km/h...

============================================================
ASSISTANT: **Weather**
Forecast for Haifa, Israel on 2026-02-02:
- Temperature: 16.8Â°C to 22.3Â°C
- Max precipitation probability: 20%
- Max wind: 20.7 km/h
============================================================

YOU: what is Inverted Index?

============================================================
USER: what is Inverted Index?
============================================================

ðŸ”§ Calling tool: search_course_materials
   Arguments: {'query': 'Inverted Index'}

Searching for: 'Inverted Index'
Found 5 relevant chunks.
   Result preview:   ==================================================  ðŸ“„ Chunk 1: Introduction to Information Retrieval Probabilistic Information Retrieval Christopher Manning a...

============================================================
ASSISTANT: An Inverted Index is a data structure used in information retrieval to store the mapping between words (or terms) and their occurrences in a document collection. It's essentially an index that maps each word to a list of documents where it appears.

For example, if we have a document collection with three documents:

Document 1: "The quick brown fox jumps over the lazy dog."
Document 2: "The sun was shining brightly in the clear blue sky."
Document 3: "The cat purrs contentedly on my lap."

An Inverted Index for this collection might look like this:

* The: Document 1, Document 2
* quick: Document 1
* brown: Document 1
* fox: Document 1
* jumps: Document 1
* over: Document 1
* lazy: Document 1
* dog: Document 1
* sun: Document 2
* was: Document 2
* shining: Document 2
* brightly: Document 2
* in: Document 2
* clear: Document 2
* blue: Document 2
* sky: Document 2
* cat: Document 3
* purrs: Document 3
* contentedly: Document 3
* my: Document 3
* lap: Document 3

This way, when a user searches for a particular word or phrase, the Inverted Index can quickly retrieve the list of documents where that word appears.

In practice, an Inverted Index is often implemented as a hash table or a balanced search tree, allowing for efficient lookups and updates. It's a fundamental data structure in many information retrieval systems, including search engines like Google.
============================================================

YOU: