Fast Fourier Transform, שהוא רלוונטי אגב בסוגריים לאינפוט דיסקרטי בפרימים, ול-Inverse Fast Fourier Transform. אוקיי, אז כל הדבר הזה, אני מקווה שהיה קצת הקדמה, שמבינים את התהליך של איך אנחנו לוקחים סיגנל מחובר של הדבר הזה שאנחנו רואים פה כוקטור עמודה, נגיד שזה הסיגנל שלנו, אנחנו מכפילים אותו בכל מיני תדרים משוארכים וככה אנחנו מקבלים Output של תדרים, ככה אנחנו עוברים ממישור של ציר הזמן למישור של ציר התדר, זה התהליך של FFT. אוקיי, אז הוא פותר מסתבר גם בעיות כמו פולינומיים, פעולות על מטריצות ולא רק בצורה מאוד מהירה, ולא רק חילוץ של תדרים במה שנקרא Spectral Analysis.

אוקיי, אז אחרי הקדמה הזאת אנחנו נציג תהליך שאת רוב המושגים למדנו, ואנחנו מכירים בצורה כזאת או אחרת, אני לא מצפה שעכשיו תהיו מומחים בסיגנל פרוססינג או משהו כזה, אבל כן להבין את התהליך שאנחנו עוברים שהוא כל כולו ניסיון לחכות את מה שקורה באוזן האנושית. אוקיי, אז בעצם אנחנו עושים תהליכים שחלק מהם הם תהליכים של כל מיני פילטרים והרחבה וקיבוץ של האותות או של התדרים, וחלקם זה כל מיני טרנספורמציות כמו ה-FFT שירנו עכשיו. אוקיי, אז יש לנו בתור הדוגמה הזאת כאן, זה דוגמה סינתטית כמו שהיה לנו גם בעיבוד תמונה דוגמה סינתטית, וקרדיט לג'מיני שעזר לי לייצר את הדוגמה הסינתטית.

אז בשלב ראשון אנחנו עושים ככה הגברה של התדרים הגבוהים, נותנים להם יותר עוצמה ואז קוראים לזה פרי-אמפסיס לתהליך הזה. אוקיי, בעצם זה מה שאנחנו עושים, תדרים הגבוהים, אלה שנמצאים יותר למעלה, בכל מקרה זה מניפולציה כזאת שאנחנו עושים לתדרים הגבוהים. בשלב הבא דיברנו על זה שאנחנו מחלקים, לא מתייחסים לאקול-אקול אלא לוקחים איזשהו חלון, אוקיי, לפי אלגוריתם של האמינג, עושים האמינג ווינדאו, אוקיי, מה שאנחנו רואים, אם אתם שמים לב, התדר חזר על עצמו, רואים את הקו הכחול חזר על עצמו, כל הזמן אותו דבר, עכשיו במקום זה אנחנו רואים תדר בחלון, בוא נצייר את זה רגע בחלון הזה, נגיד מכאן עד לכאן, נגיד בערך אותו דבר כמו שהיה במקום, אבל אחרי זה הוא מתחיל לדאוך וגם עד אליו הוא כאילו חלש כזה, ואז פתאום זה התופעה, החלון של האמינג הוא לא ככה מחבא לגמרי את מה שהיה לפני אחרי, אלא הוא עושה את זה בצורה דרגתית יותר, אוקיי, זה ככה קצת בנפנופי ידיים אני יודע, ויש לו איזשהו מטרה לעזור לאלגוריתם של 0-T, עוד איזשהו תהליך של איבוד מקדים, אז לאחר מכן זה קצת יותר, נכנסנו לעומק, דיברנו על זה שאחרי זה אנחנו עושים, מבצעים 0-T, אוקיי, אני מנסה לראות אם כאן יש לנו, כן, אז זה היה התדר המקורי, רגע, במיקרו שניות אני חושב, כאן, אוקיי, וציר ה-Y זה העוצמה, המאמפליטודה, אוקיי, בשלב הבא, אנחנו רוצים לדמות את התהליך של מניפולציה על תדרים גבוהים שנעשה באוזן האנושית, זה התדר הקטון הזה, ביחס לתדרים גבוהים, מה שנקרא high-pass filter, אוקיי, boosted high frequencies, זה מה שה-high-pass filter עושה, והיחידות שאנחנו נעבוד איתן, אותן פריימינג, הן יהיו בגודל של 25 מיליסקנז, ונעשה את החלוקה לאותן יחידות בעזרת coming windows, שלא אמרתי איך עושים את זה, אוקיי, רק תיארתי את מה שאנחנו רואים, לא הסברנו את זה, ואחרי זה, על הדבר הזה, אנחנו עושים, לא מחקתי פה את הכישקושים שלי, על הדבר הזה אנחנו מפעילים את ה-fast Fourier transform, אוקיי, על האינפוט הזה, אז זה מה שאנחנו מקבלים, אנחנו רואים שאין לנו, אי אפשר להשוות כי זה לא אותו ציר, זה ציר של תדרים, אני רוצה טיפה-טיפה להסביר מה אנחנו רואים כאן, האוזן האנושית יכולה לשמוע עד תדר של 20,000 הרץ בערך, אוקיי, זאת אומרת שבשביל לייצר את זה, אם אתם זוכרים, אנחנו צריכים קצת יותר מפי שתיים דגימות בשביל זה, נגיד 41,000 דגימות בערך, אוקיי, כדי שנוכל לשמוע את כל התדרים, כאילו לחלץ את כל התדרים שהאוזן האנושית שומעת, אוקיי, כמו בסיגנל ויזואלי, גם בסיגנל שמיעתי, אודיו, אנחנו שמע, צריך להגיד, בסיגנל של שמע אנחנו מתעלמים ממה שהבן אדם לא רואה או שומע, כי בעצם עושים פה איזשהו תהליך של הדמייה לבני האדם.

בשלב הבא אנחנו עושים עוד איזושהי מניפולציה שלכאורה נעשית אצל הבן אדם, קוראים למניפולציה הזאת מל, שכחתי אם זה קיצור של מה, סקיילינג, אוקיי, אז זה בעצם התהליך של המל סקיילינג, בצד ימין אנחנו רואים את התדרים השונים, מה שאנחנו נראה בצד שמאל זה האטפוט של התהליך הזה, הוא ייקח את הדבר הזה וימיר אותו למשהו שנראה כמו התהליך הזה, שבעצם מדבר על הקפיצות שיש לנו בתדרים בין הפיקי מלמעלה, כאילו אם עטפנו את התדרים בצורה הזאת, הסתכלנו מבט מלמעלה, אוקיי, קוראים לזה האנבלופ של המעטפת של התדרים מלמעלה, אז אנחנו מקבלים משהו שנראה ככה, וזה מה שאנחנו מייצרים במל סקיילינג הזה, אוקיי, אז אם נריץ על הדבר הזה את המל סקיילינג, אז אנחנו נקבל משהו כזה, אוקיי, ככה נראה אחר המל סקיילינג, לאותו תדר, כן, לתדר הזה, אוקיי, ועל הדבר הזה אנחנו עושים שלב אחד לפני התהליך החשוב של ifft, אנחנו מעבירים על הדבר הזה log, אוקיי, ובעצם על ה-log אנחנו נעשה setString, עכשיו אני רוצה להגיד שלפעמים בתהליכים של העיבוד של האות, אנחנו, חלק מהשלבים האלה שהתבררו כמועילים אנחנו לא נראה, זה לא השלבים הבסיסיים, השלבים הבסיסיים זה יהיה איך שהוא לחלק את זה לאיזשהו פריימינג, לחלון, ולא, כאילו, ב-basic, באלגוריתם הבסיסי אז לא מדברים על ה-pre-emphasis, כי זה שלב שהוספנו שהוא כן נעשה חלק מהתהליך אבל הוא לא השלב הבסיסי ביותר, ה-fast Fourier Transform כמובן גם נעשה, המייל פילטרינג גם או סקיילינג גם לא רואים את זה בכל התהליכים הבסיסיים, זה עובד על תדרים גבוהים וזה על תדרים נמוכים, זה עושה את הקפיצות בתדרים הנמוכים הגבוהים, ובמייל סקיילינג מכפילים את התדרים על ידי, לצורך העניין, תדרים כמו שאנחנו רואים בצד ימין, הפילטר בנק הזה, מכפילים אותם בדבר הזה, והדבר הזה כפול לדבר שבצד ימין, האוסף של התדרים האלה שאנחנו מכפילים, נותן לנו את הקפיצות האלה שאנחנו רואים בסוף ב-output, שזה בעצם נותן לנו מעין מעטפת על כל התדרים האלו מלמעלה, זה קצת בנפנופי ידיים, אני יודע, הכל מבוסס כאן על low frequencies, ה-differences, ההפרשים בין ה-low frequencies, כאן אנחנו מסתכלים בעצם על הדיפים בדבר הזה ופחות על התדרים עצמם, כאילו כמה קפצנו מהתדר הקודם, הנמוך הקודם, זה ככה, אני יודע, אבל אין אפשרות להתעמק הרבה יותר מזה, אז בגלל זה אני גם מנסה לחלק בשלבים היותר קליטיים והפחות, את השלב של ה-log, אז לפעמים אנחנו נראה את ה-log על הדבר הזה ולא על המל-scaling הזה, ואז אחרי שעשינו log, הנה כאן אנחנו רואים נגיד תהליך שהוא לא כולל את השלבים האלה, יש לנו את ה-time, כן, את זה עשיתי, לקחתי מויקיפדיה לדעתי, יש לנו את הסיגנל המקורי, כן, תלוי זמן, ויש לנו את החילות של התדרים, הספקטרום אנליסיס כאן בצד ימין, ואז עשינו log על הספקטרום, אוקיי, קיבלנו את הדבר הזה, אצלנו כאן בדוגמא כאן עם קוד שמריץ אותה, זה מבוצע על המל-scaling הזה, לא על הספקטרום ישירות, ועל הדבר הזה אנחנו עושים ifft, על ה-ifft קוראים לזה ספסטרום, אני מכיר את זה בעיקר מזיהוי דיבור את הטרמונולוגיה הזאת, כל השאר בגלל כל המניפולציה הזאת שעשינו במישור של התדר, ואז החזרנו את זה לסיגנל המקורי, למישור המקורי, אז הכל אומרים את זה בהיפוך, אז במקום frequency קוראים לזה קוויפרנסי, ובמקום ספקטרום קוראים לזה ספסטרום, אוקיי, אז אנחנו עכשיו בעצם מגיעים לשלב של הספסטרום, אוקיי, אז זה קודם כל עשינו log, ואז עשינו לזה iDST, אוקיי, זה נמצא כאן, אוקיי, זה השלבים בעצם שעשינו בכל התהליך הזה, עשינו log, iDST, יש גם low pass filter, שזה בערך התהליך של המייל סקלינג הזה, ואנחנו מקבלים בעצם את החלוקה הזאת של ה-coefficient של ה-frequencies השונים, אוקיי, שבציר ה-X יש לנו כאן את ה-coefficient index המקדמים, אני חושב שהם מקדמים של התדרים השונים, אוקיי, השלבים האלו זה השלבים החשובים שצריך לדעת, יש לנו את התדר המקורי, עשינו עליו FFT, העברנו למישור התדר, זה מה שאנחנו רואים למעלה בצד ימין, על הדבר הזה לצורך העניין דילגנו על שלבים, עשינו log, ועל הדבר הזה עשינו inverse FFT, אוקיי, אני כן אגיד שכל הדברים האלה קראנו להם FFT, אבל עשינו את זה עם התמרת קוסינוס, לא עם התמרת FFT, כאילו FFT מורכב גם מזווית וגם מאמפליטודה, והקוסינוס לוקח רק את התדר של האמפליטודה, והוא מתעלם על השינויים בזווית של הוקטור כל הזמן, בסדר, זה מאוד בגדול, אני יודע שקצת הסתבכנו, התהליך הזה זה תהליך שמחכה את המוח האנושי, ומסתבר שהוא מאוד מאוד יעיל כחלק מהחילוץ של הפיצ'רים, אז כרגע גם אם זו קופסה שחורה, יש לנו את ארבעת השלבים האלו, לקחנו סיגנל, העברנו אותו לתדרים, עשינו על התדרים log, והחזרנו את זה למישור של סיגנל, אבל אחרי המניפולציה של ה-log בתדרים, אחרי ה-log, ה-log של התדרים, יש את המישור של ה-time, מישור הזמן, שהציר ה-x הוא זמן, והיית מישור התדר שציר ה-x הוא התדרים, אוקיי, למעלה בצד ימין זה מישור התדר, למעלה בצד שמאל זה מישור הזמן, בסדר? האמפליטודה של התדר הוא 100? האמפליטודה של התדר היא 1000. התדר הוא 100. זה 0, 100, 200, 300 זה התדר עצמו, זה התדר ההרמוני.

בסדר, ציר ה-x הוא התדר. טוב, אני יודע שזה קצת מסובך, זה הולך להיות, זה החלק הקשה עד עכשיו היה. אוקיי, למה זה מעניין אותנו כל הדבר הזה, אוקיי? בשביל מה הראינו את הכל? אז בסוף, לא התכוונתי לעשות את זה.

ראינו את ה-log כאן, זה מה שקיבלנו אחרי ה-log לצורך העניין, ואז עשינו inverse discrete Fourier transform, ואז קיבלנו את הספסטרון. בסדר? חזרו את הגרפים, אוקיי? קחו את הגרפים מכה. הבנו את התהליך שעשינו? טכנית, קראנו לפונקציה זאת, לפונקציה זאת ולפונקציה זאת.

אז זהו, אז בואו נזכור רק את זה. בואו נזכור רק את זה. רק מה שכן חשוב לקחת מהתהליך, אולי בכל זאת הציור ימחיש את זה, זה שבסוף יש לנו אוסף של תדרים בלתי תלויים, כאילו אוסף של וקטורים בלתי תלויים, וזה חלק ממה שמעניין אותנו בסוף ב-output שאנחנו עושים, יוצרים חוסר תלות ביניהם.

אוקיי, אז זה היה הרבה ונפנפי ידיים, אני יודע. עכשיו כל הדבר הזה, אנחנו משתמשים בו מקבלים את אותו ספסטרום וזה מה שאנחנו יודעים לעשות איתו. אותו קלאסטרינג שדיברנו עליו קודם, אז הספסטרום זה בעצם הפותח מסוג של וקטור שאנחנו עובדים איתו עכשיו.

כל הדבר הזה, יצרנו פותחweight של וקטור שאנחנו קוראים לו ספסטרום, למקום חדר, ספסטרום, פשוט הפכנו אותו סדר של אותיות, ככה כותבים אותו. והדבר הזה משמש לנו או לפחות במודל הקלאסי שימש לנו כאינפוט לזיהוי של מילים אוקיי, כאן יש לנו משהו הרבה יותר פשוט ממילים יש לנו בעצם כאילו וקטורים שמייצגים את הצליל אולי אה משהו כזה וזה את הצליל אי וזה מייצגים את ההפסקה של הדיבור בין לבין אוקיי, אז יש לנו כאן שני מימדים, שני פיצ'רים וזה התהליך של הקלאסטרינג, רק במקום קיימינג זה פעם עם אלגוריתם מסתברותי על בסיס שילוב גאוסיאנים למי שמכיר למי שלא מכיר ולא למד רק לזכור שזה תהליך של קלאסטרינג מה אומר התהליך של הקלאסטרינג? שאין לנו תיוג על הדוגמאות אוקיי, אנחנו כן יודעים להגיד עם דוגמים קצת שזה היה צליל אה וזה היה צליל אי וזה היה שקט אבל לצורך העניין לא תיאגנו את כל הדוגמאות ועשינו משהו מונחה תהליך כמו סיווג, קטגוריזציה, אלא עשינו קלאסטרינג מה שמיוחד בקלאסטרינג הזה זה שזה הסתברותי כלומר אפשר להגיד מה הסיכוי שכל אחד מהווקטורים שייך במקרה הזה לשלושת האפשרויות כן, כן, כן, זה סתם בשביל ויזואליזציה, כן אוקיי אז שוב, עשינו תהליך, בואו נחזור עליו ממש בקצרה לקחנו את הסיגנל, העברנו אותו בעזרת FFT למישורות עדן עכשיו אני מדלג על כל הדוגמאות היותר מסובכים עשינו פונקציית לוג וחזרנו את זה עשינו inverse FFT וזה עכשיו הוקטור שם וזה אנחנו קוראים ספסטרום ועל הספסטרום הזה עשינו קלאסטרינג בעזרת GMM וזה התוצר שקיבלנו, יש לנו שלוש אפשרויות אחד פשוט הצליל A, אחרי זה צליל E ואחרי זה הפסקה בין הצלילים לצורך העניין או לפני הצליל בסדר? זה החלון רץ על הטדר או שכל פעם כשאנחנו עושים חלון רץ זה חלון רץ? שאלה טובה, אני חושב שזה חלון רץ לא זוכר בדיוק בכמה המישור של הזמן זה ההשתנות של הגל לאורך הזמן ההשתנות של האמפליטודה ושל הזווית יש לנו זווית של השמה, לא משנה כרגע מה השמה אומר בדיוק הזווית והעוצמה זה המישור של הזמן איך זה משתנה לאורך הזמן, זה הגל הזה שהיינו בתחלה ומישור של הטדר, ציר ה-X זה התדרים כל התדרים הארמונים לצורך העניין יש לנו משהו כמו עשרים אלף תדרים ארמונים שבן אדם יכול לשמוע וציר ה-Y זה העוצמה גם משהו כזה אז עכשיו כשאנחנו עובדים עם הספסטרום אחרי התהליך הזה אפשר לעשות לזה קלאסטרינג, זה קלאסטרינג הסתברותי מה שאפשר לנו קצת גמישות ואחרי זה נדבר גם על מה אנחנו עושים עם ה-GMM הזה עוד תהליך שאנחנו השתמשנו בו בעבר בזיהוי דיבור כולם למדתם פה גרפים באיזשהו קורס? אוקיי? אנחנו לא נכנס לעומק לגרפים אל תדאגו, זה יהיה גרף הרבה יותר פשוט ממה שאנחנו רואים כאן מי שלמד קורס של אוטומטים אז זה מאוד מזכיר מעבר ממצב מסוים למצב אחר או חזרה לאותו מצב כאן יש לנו הסתברויות על הקשתות אוקיי? מה זה אומר? שאנחנו לא בטוחים מה הקשר בין זה לענייננו? אנחנו לא בטוחים מתי נגיד נגמר צליל מסוים ומתי עברנו לסוג אחר של צליל אוקיי? אז אנחנו לוקחים בעצם לצורך העניין את ה-GMM בתור כלת על איזה מצב אנחנו, על הסיגנלים השונים ואז אנחנו אומרים עכשיו כשעבר כך וכך זמן בפריים הזה האם עברנו לצליל מסוים אחר או שנשארנו באותו צליל אוקיי? והדבר הזה עושים באזור התסתברויות אז זה אלגוריתם של עידן מרקוביאן עידן מרקוביאן מודל אוקיי? לאלה מביניכם שלמדו בקורס הסתברות אני בטוח שלומדים את זה בטח לומדים בסתברות חוק בייס מי שלמד למידת מכונה אז בטח מכיר את אלגוריתם נאיב בייס אוקיי? אז הדבר הולך ככה אז אני אסביר ממש ממש בכלליות מה הרעיון? הכל נובע מההידן מרקובין אנליסיס נגיד אוקיי? בעצם אנחנו אומרים שאם אנחנו נמצאים בסטייט מסוים קודם כל אנחנו מניחים שלא משנה מה נקודת הזמן שבה אנחנו נמצאים זה לא חשוב. נקודת הזמן לצורך העניין למי שמכיר באלגוריתמים של קריאת גרפינג כמו DFS אם למדתם אז יודעים שהזמן זה לא ציר הזמן באמת זה כאילו עבר כך וכך סטייטים בגרף מאז שהתחלנו לקרוא אותו אז זה הזמן שלנו. 

אז זה כאן אנחנו אומרים שלא משנה כמה זמן עבר מההתחלה אלא חלק ראשון של ההנחה שמשנה מה היו הסטייטים שהיינו קודם אז זה כבר הנחה מכילה אחת והנחות מרקוביות שונות זה בעצם אומרים כמה סטייטים אנחנו לוקחים בחשבון אז הנחה מרקובית מסדר 0 אומר שרק המצב שבו אנחנו עושים עכשיו משפיע על ההסתברות שלנו מסדר 1 רק המצב הקודם משפיע סדר 2 שתי מצבים קודמים משפיעים על ההסתברות שאלה אנחנו נמצאים עכשיו וכן הלאה אז HMM בעצם עושים הנחה מכילה מי שלמד אולי אלגוריתמים חמדניים אז מכירים קצת את ה... אנחנו מגיעים ממקום למקום ורוצים לדעת מהי המסלול האופטימלי אז בעיית הסוכן הנושאה אם שמעתם עליה זה יקרה מדי אין פיקשה אז במקום זה הולכים רק המצבים קדימה אז עושים משהו דומה כאן עם ההנחה מרקובית אנחנו שמענו סליל מסוים נגיד אנחנו יודעים שאתמול ירד גשם ושלשום לא ירד גשם אז אנחנו שואלים מהשתי הימים האלה מה הסיכוי שהיום ירד גשם נגיד אם נדמה את זה למשהו שמכירים ולא נלך עכשיו מאה ימים אחורה ונבחן את כל אלה אז זה הרעיון של משהו דומה להנחה מרקובית מסדר שני אוקיי אז אם לקחנו את ה-GMM ככלת ויש לנו אני מזכיר שלוש מצבים דממה, הצליל A והצליל E אוקיי ועכשיו יש לנו כאן מטריצת מעברים ממצב למצב מה ההסתברות שנעבור ממצב מסוים למצב אחר אוקיי עכשיו ההסתברות הכי גבוהה זה להישאר באותו מצב נגיד אם היה דממה קודם, הסתברות של 0.8 שאנחנו עדיין בדממה וההסתברות של 0.2 מסתבר רק לעבור לצליל של A לא לצליל של E והצליל של E אפשר לעבור רק אם היינו קודם בצליל של A או שהיינו קודם גם בצליל E אוקיי זה בעצם מה שאנחנו רואים כאן, את ההסתברויות שלנו מעברים עם זה התוצר של ה-HMM לצורך העניין, המטריצה הזאת כאן מה ההסתברות לעבור מכל מצב לכל מצב אם סוכמים כל שורה רואים שמגיעים לאחד אוקיי אז זה הרעיון אני לא אכנס לזה, היה מחשבה להיכנס לזה אבל אני אגדלג על זה האופטימיזציה שאנחנו עושים לדבר הזה נעשית בעזרת אלגוריתם ידוע בתחום הזה שנקרא אלגוריתם של ויטרבי בעצם אנחנו פותרים את זה בצורה אקורסיבית ומה שאנחנו רוצים לעשות זה תהליך כזה של מכירים בעיות אופטימיזציה, נכון למצוא מקסימום ומינימום של ערך מסוים לכל מיני בעיות אלגוריתמיות אז בעצם כאן אנחנו עושים על הגרף כאילו ההסתברויות זה משקולות כן ההסתברויות של הקשתות זה משקולות ואז אנחנו רוצים מקסימיזציה כלומר מה המצב יש לנו בעצם עכשיו חלוקה על ידי ה-GMM בשלב נחשוב ונסכם עוד טיפה עשינו, לקחנו את הסיגנל הפכנו אותו לספסטרום ועל הספסטרום הרצנו קלאסטרינג כן הרצנו על זה קלאסטרינג ועכשיו יש לנו הסתברות לכל אחד מהמצבים, עבור כל אחד מהווקטורים לצורך העניין כמספר המצבים האפשריים יש לנו הסתברויות, יכול להיות בין 0 ל-1 הכל כאשר לכל נקודה כמובן צריך לסכום את זה ל-1 אז זה בעצם התוצר של ה-GMM וזה נותנים ככלת ל-HMM ההידן מרקוביאן מודל והוא בעצם יוצר לנו את הדבר הזה את המטריצה של המעברים ממצב למצב זה גרף כזה, המטריצה הזאת מתארת גרף וכאן אנחנו רואים את ההסתברות למעבר ממצב למצב עכשיו את הדבר הזה אנחנו עכשיו לוקחים את הסיגנל ואומרים בעצם איך אנחנו עושים דיקודינג למה שהבן אדם אמר לצורך העניין אז כאן אנחנו רואים תהליך די מורכב להפוך את הסיגנל של האות לספסטרום בסוף לעשות על זה קלסטרים בעזרת GMM ואז מתוך איזשהו מסווג של HMM אנחנו מחליטים מה אמר הבן אדם זה התהליך שהסיגנל עובר עד שאנחנו מבינים במה דובר זה עוזר או שזה ברור? זה ספסטרום שני, ולא בכלל מהמורכב זה נקודת זמן הספנסית יותר בעצם כל אחד מהנקודות האלה 5 מיליסקונד שנתקשנו וכמעט עכשיו המטריצה שהראית אומרת עכשיו אני בנקודה של A עכשיו מסדרים את זה על ציר הזמן את כל הנקודות השונות ובכל אחד בעצם יש הסתברות שאנחנו נשארים באותו צליל או שעוברים לציל אחר מתוך הצלילים האפשריים שיש לנו שבמקרה הזה זה סיילנס, A וE זהו, זה שלושת האפשריות שלנו אז כל אחד מהנקודות יכול להיות או פה או שם אז בעצם מתקבל איזשהו רצף שמתוך זה מסיכים מה הבן אדם אמר לא ברור? אני מבין לי לסדר את זה על רצף הזמן הרצף הזמן נותנים את זה כאינפוט לדבר הזה ל-HMM ה-HMM למד מטרינינג סט, זה סופרווייז לרנק הוא למד הוא קיבל הרבה, לא רק את הסיגנל הזה הוא קיבל מלא סיגנלים והוא למד בהינתן רצף כזה איך אני, כאילו מה הסיכוי במצב מסוים בהתאם למצבים הקודמים שאני עכשיו נמצא בצליל של סיילנס בצליל של A או בצליל של E מה הסיכוי לעבור למקום אחר בגרף ומה הסיכוי להישאר באותו סטייפ הוא, בהסתברויות שונות כל אחד יכול להיות שייך לכל הקלאסטרים בניגוד לקיימינס, בקיימינס יש לנו רק שייכות אחת לקלאסטר כאן יש תוצר דומה לקיימינס אבל עם הסתברות לכל הקלאסטרים כל אלה שבהסתברות אוהבים כמעט יש לנו כאן שני דברים יש לנו את הסטייט שאנחנו נמצאים בו כרגע נגיד זה סיילנס אוקיי, עכשיו קיבלנו את ה Output מה-GMM אז השאלה היא עכשיו בהינתן ה-Output הזה שזה בעצם וקטור הסתברויות לכל אחת מהאפשרויות מה הסיכוי שעכשיו אנחנו נשארים בסיילנס או עוברים לכל אחד מהם יוצר חץ כזה בגרף כאן כן, ה-A12 זה נגיד המעבר בהינתן Output מסוים מה-GMM אוקיי, אז אנחנו נעבור בהסתברות מסוימת ל-X2 בסדר? לא דיברנו בכלל על אלגוריתם וטרבי ועל איך לומדים את ה-HMM שזה Overkilling לשיעור הזה נראה לי גם ככה עשיתי לכם Overkilling בשיעור הזה אז לא נדבר על איך אבל בעיקרון לוקחים את ה-Output מה-GMM והוא בעצם נותן לנו אינפוטים למעברים במכונת מצבים הזאת ההסתברותית אבל ה-HMM זה כמו מכונת מצבים הסתברותית שהחצים אומרים לנו בהסתברות שונה מעבר מ-State אחד לסטייט אחר והסטייטים בעצם זה הקטגוריות שלנו בסדר? לא? עוד פעם? כאילו תשאלו או תתפנו אותי למה לא ברור נגיד עכשיו הכל הזה גילה שיש פעמים אה אה ואז לפי ה-HMM הוא רואה אותה הסתברות הכי גבוהה רבה שזה יהיה אי אז הוא משלים את זה ואי הוא לא יכול להשיג את זה מה-source מה זה? הוא לא יכול לעשות איזה פרדיקציה למה שאני צריך לדעת מה ההסתברות למצב הבא כשיש לי את ה-Input אוקיי יש אלגוריתמים שלא עושים את זה ברצף עושים את זה רק בבקטור אחד שהם נקראים Maximum Aposterior Probabilities או Maximum Likelihood Probabilities שבעצם עושים מקסימיזציה להסתברויות מה המצב אז ה-HMM לוקח את זה למה המצב הסביר ביותר שנמצא בו כרגע בהינתן שקיבלתי עכשיו Input כזה ובהינתן המצבים הקודמים שכבר הגעתי להם אוקיי זה תהליך שיודע לקחת כמה סטייטים אחורה ולקחת אותם בחשבון אז לצורך העין הסטייטים הקודמים היו לפרימים כאלו ועכשיו מה הסיכוי שעכשיו אני בהינתן הקלט הזה היה לי המון דוגמות אימון אז אני יודע מה הסתברויות השונות למעברים בהינתן הקלט הזה מה הסיכוי שאני עובר למצב אחר או נשאר במצב הנוכחי ואז מכל הדבר הזה אנחנו יודעים להקיב מה בן אדם אמר בסוף עכשיו זה מאוד מצומצם, מאוד מסובך ביחס לאפשריות שיש היום כי זה היה מאוד מוגבל בגלל זה מערכות אוטומטיות שהיו מאוד מורכבות בעבר, אז מה שהיו מאמנים אותם לעשות זה מי שמכיר לעשות זהוי מילות מפתח למשל, היום למי שלא יודע יש למשטרת ישראל קו 105 להגנה על ילדים, מכירים את זה? מוקד 105 אם יש ילד קטן שסובל מפגיעה מנית חס וחלילה אז אני לא אגיד שיש מאמץ גדול של משטרת ישראל יש מאמץ קטן לעזור אז יש אנשים שנגיד מתחזים לילדים כדי לתחוס פדופילים וכל מיני דברים כאלו לא שמעתם על זה אף פעם? לא משנה אנחנו לא בעסק בזה אני לא בעסק של משטרה או של הפדופילים? אני מקווה שלא השני לפחות חס וחלילה זה לא מצחיק לא מצחיק הרעיון הוא שנגיד שיש איזה מעקב אחרי משהו שמישהו אומר סיגנל ווייס, ומישהו אומר איזה מילה שלא במקום אז ממש לעקוב אחרי הכל זה ממש אי אפשר, לא היה אפשר טכנולוגית לעשות בעבר אבל למצוא איזה מילת מפתח מסוים אז אם היו בונים ככה מחשבים כבדים מאוד אז זה היו יכולים לעשות, כמו שכאן אנחנו רואים רק לשלוש צילים בונים מכונת מצבים מסובך כזאת ה-HMM, זה הטכנולוגיה שהייתה זמינה בזמנו ו זה כאילו מה שפוענח נגיד במקרה הזה, שהיה סיילנס, א, אי, ואז סיילנס זה מה שיפיע נכון נגיד בדוגמה הסינתטית הזאת אוקיי, מכל המצבים, למה? כי זה היה הרצף עם ההסתברות המקסימלית אוקיי, אז לסיכום, זה היה התהליכים שעברנו, היה אולי עדיף כאן בסיכום הזה להוסיף גם את התהליכים שהסיגנל עבר, אבל את זה לא עשיתי נראה לי שחזרתי על זה איזה 500 פעם, אז לא יודע, אז יש לנו פה את ה-GMM שהתקבל כאינפוט ל-HMM, אימנו HMM ואז נתנו את הסיגנל והוא הוציא בעזרת אלגורית NV-Therby את הרצף המקסימלי של מה שאמרו בסיגנל, אוקיי אז עכשיו אז דיברנו על כל המרכיבים, עכשיו מה שנשאר לנו זה לתת כמה דוגמאות אוקיי, ואז לחבר את זה למערכת הירד, כמובן כי בכל זאת אנחנו בקורס הירד אז אחת מהמערכות שאנחנו נדבר עליה זה הזכרנו אותה קודם, זה זיהוי לפי התדרים האם הדובר זה דובר או דוברת אוקיי, יש כמו שאפשר לראות כאן תדרים נמוכים יותר, כן בטח שמעתם, יש לך קול מאוד נמוך או קול גבוה יחסית לנשים ולילדים אוקיי, אז רואים פה את התדרים טווח התדרים הממוצע שיש לנשים ולגברים אוקיי, אז אנחנו רוצים לקחת את אותו ספסטרום ולזהות האם מדובר בזכר או נקבה, זה המשימה שיש לנו כרגע ובשביל לקחת את הוקטור לזהות אם מדובר בדובר או דוברת כמובן שזה רק דוגמה לחילות של פיצ'ר מסוים, אפשר לחלץ עוד כל מיני דברים בצורך העניין לזהות אם בן אדם בלחץ נגיד, או מישהו מאוד כועס אולי גם לפי התדרים אז כאן אני רוצה להציג משהו שדובר עליו קודם, זה רק מבוא בלי להיכנס למתמטיקה, אבל מה זה SVM? באמת במבוא למה אני מציג את זה? כי בדוגמה פה פשוט השתמשנו בSVM, זה הכל אז כאילו אנחנו על הדרך ככה מציגים כל מיני דברים שקשורים ללמידת מכונה אבל באמת לא לעומק אז אם אתם זוכרים, היה לנו את האלגוריתם של נוירון מלאכותי בודד Perceptron Logistic Regression ששם חיפשנו מפריד שמנסה למצוא הפרדה טובה בין דוגמאות חיוויות ושליליות אז כאן במקום חיוויות ושליליות יש לנו את אני לא יודע מה זה רזולוציה לא מספיק גבוהה אם זה מעוינים או מה זה לא יהיה כחולים והמשולשים האדומים זה המקום חיווי ושלילי אוקיי? אז זה נתחיל ככה בכמה שאלות אז אם היינו שואלים איזה מפריד עדיף? אינטואיטיבית מי שמכיר אולי יופי אז מה עדיף את המפריד שמסומן כאחד או כשתיים בין המפלגות אוקיי אז מה יש כל אחד לאחד אוקיי אתם צודקים את אומרת שתיים אוקיי אז נסביר את זה כבר זה יותר טוב ולמה זה עדיף? אז זה קשור לאלגוריתם של SVM בעצם במקום לחפש מפריד ב-SVM מחפשים שוליים בין החיובים לשליליים כאשר המטרה בעיקרון שהחיובים יהיו מעל השוליים והשלילים יהיו מעל השוליים נגיד הקו המקווקו הסגול העליון והשלילים נגיד יהיו מתחת לקו המקווקו התחתון ואז זה לא ניכנס לזה המתמטיקה פה יותר מסובכת מאשר ב-logistic regression אז יש לנו פה בעיית מקסימיזציה עם סיפוק אילוצים אוקיי יש לנו פה שתי אילוצים או שתי סוגים של אילוצים אין אילוצים כאשר אין זה כמות הוקטורים בטרנינג סט בדוגמאות שאותם תיאגנו כחיוביות ושליליות או במקרה שלנו כ תדר שמבטא אישה או תדר שמבטא איש, גבר או אישה אוקיי, אז במקום להגיד אנחנו רוצים הפרדה שזה יהיה שטח של החיובים וזה של השלילים, אז אנחנו מנסים לייצר משהו יותר שאני מרווח ביניהם, זה אותו margin אוקיי, אז אם כבר שואלים אז נשאל שאלה דומה לשאלה ששאלנו קודם מה עדיף? האם עדיף המרג'ן מספר 1 או 2? תסתכלו רגע מה עדיף? 1 או 2? תנו לי כמה אתה רוצה סבבה זה אחד שמכיר, מה? זה אחד שמכיר, מה? לא, הוא אומר שזה לא, לא, לא אמרתי שאת רעש אני רק שאלתי מה חושבים זה אחד אוקיי, למה? כי בעצם אתה רוצה שיהיה לך מרווח מקסימלי בין שתי הקצוות בין שתי המחלקות לצורך העין אתה כבר הכנסת את הידע שלך כשאמרת קצוות באמת כאן יש לנו מרווח גדול יותר ואנחנו שואפים למרווח מקסימלי בטרנינג סט אוקיי? לא ניכנס שוב למותמטיקה אבל בעצם עושים את הדבר הזה באמת על ידי הקצוות, אנחנו מניחים שאם אנחנו מוצאים קבוצה אז מה שיעזור לנו להחליט אם זה שייך לקבוצה א' או לקבוצה ב' זה לא הדוגמאות שבאו מאליו לאיזה קבוצה המשייכות אלא הדוגמאות הגבוליות אוקיי? לאותן דוגמאות גבוליות אנחנו נגדיר אותן כגבוליות אם הן יושבות על הקצה של השוליים האלו ונקרא להן support vectors support vectors זה קיצור של support feature vectors זה צורך העניין והכוונה היא לצרך לפחות וקטור אחד חיובי ואחד שלילי זה המינימום, דרך כלל שואפים לי יותר ועושים את כל התהליך הזה מתמטית אם הם קדמי לגרנג' אבל לא ניגד בזה אז זה בעצם מה שמחפשים ב-SVM ומה שהתייחסת אתה קודם זה שיש עוד גרסה יש hard margin ויש soft margin מה שאמרנו קודם שהמטרה שלנו היא להפריד לגמרי בין חיובים ושלילים ההפרדה הזאת היא הפרדה ליניארית אבל אף אחד לא מבטיח שיש הפרדה כזאת אז יש גרסה של SVM זה הדבר היחיד שאני עוד מוסיף פה יש עוד כל מיני מניפולציות אבל נעזב אותם שמאפשרת גם לאלגוריתם קצת לטעות עד גבול מסוים אם אני אישר אותו על טעויות בתנאי שהוא מוצא margin ככה יפה והcc לצורך העניין זה לא מתמטי בכלל זה רק נותן לנו את המוטיבציה למה שאנחנו רואים פה עכשיו בעצם אותו רעיון בעזרת SVM לצורך העניין הפרדנו בין הוקטורים של הספסטרום שמייצגים נשים וגברים אם חדי העין זה גרסה של סופט SVM יש לנו קצת גלישה פנימה בשתי הצדדים ואלו הוקטורים שעומדים על הקווים המקווקווים זה ספורט וקטור כל הדבר הזה הוא אם תרצו לא יודע מה הגדר סביב המפעל שאף אחד לא יפרוץ גם אותה אבל בעצם לא רוצים שהלכו לחדר הסודי במפעל בעצם בסוף בסוף אנחנו כן השתמש במימוצה של המרגין הזה כמבחין בין הנשים לגברים או בין המחלקות השונות ודאגנו שהוא יהיה מוצלח יותר על ידי זה שעשינו מקסימיזציה של המרגין אבל הקו האמצעי הוא זה שבעצם יהיה מפריץ זה מה שעושים בSVM אז כאן הוקטורים שלושו בספסטרום שאימנו על SVM לצורכם וקטורים שונים כאלו וככה הבחנו רגל אז זו דוגמה לתהליך אחד תהליך נוסף שהזכרנו אותו שמעניין אותנו זה להעביר את הסיגנל את כל השלבים עד ה-HMM ולזהות בעצם באיזה מילה דובר אז הדוגמה כאן כדי שנוכל לקחת את זה ל-IR זה יהיה נגיד המילה 1 או המילה 2 1 או 2 אז בעצם דיברנו אם אתם זוכרים על ניתוח מורפולוגי כשדיברנו על טקסט בזמנו אז כאן אנחנו מדברים על פונמות או בעברית קוראים לזה יצורים ועברות שמכיר, אנחנו נראה פה חלוקה כזאת לעברות וליצורים אז כאן נגיד המילה 1 כן יש איזה אלפאבט אוניברסלי לחלוקה פונמית עברית וערבית זה שפות פונמיות פונטיות מי שמכיר, אז כאילו בניגוד למנדרינית נגיד או לקוריאנית ששם יש אלפי אותיות אבל זה לא שפות פונטיות כאן אנחנו יודעים להגיד שהצליל מבוטב איזושהי אות שכותרת אותה, אפשר להבין לכי מה שכתוב בדיוק כך מבטאים את המילה בניגוד לשפות כמו מנדרינית שצריך לזכור שזו אומרת המילה הזאת שמבטאים אותה ככה וככה אוקיי? אז אז כאן יש לנו 1 הופך ל-W זה ה-ו זה ו-ה-נ כן? יש לנו שלושה מצבים וב-2 יש לנו שתי מצבים כן? זה ה-ת וה-או אוקיי? אז עכשיו אנחנו מקבלים דוגמה איזה ה-ה-ז בעצם התצוגה שלהם אחרי שהתאמנו על חמשת המצבים האלה ב-GMM אוקיי? זה מה שאנחנו רואים כאן מה? יש לנו... לא כתוב פה איזה מצב זה כל אחד אבל יש לנו שלושה מצבים ל-1 ושתי מצבים ל-2, נכון? אז זה לא ברמת המילה כאן כאן זה ברמת העיצור לצורך העניין אוקיי? והמצבים שלנו לצורך העניין זה התחלה, אמצע וסוף זה מה שאנחנו רוצים לסווג וכאן יש לנו איזושהי דוגמה של לצורך העניין נאמר 2 אוקיי? ו... יש לנו פה איזה מכפלה של הסתברויות אנחנו נעזוב את זה, אנחנו רואים פה בעצם את ה-output של ה-HMM של 1 ושל 2 2 מקבל... רואים את המעברים בצורה ברורה, ב-1 בעצם לא כל כך רואים כי זה ערכים מאוד נמוכים, זה אפילו זה לא מוצג ויזואלית ו... אם אתם שמים לב מדובר בשניהם במספרים מאוד נמוכים כאן 9.6 כפול בערך 10 בחזקת מינוס 309 וכאן 1.4 כפול 10 בחזקת מינוס 36 אבל עדיין מדובר בסדר גודל יותר גבוה ל-2 מאשר ל-1, אז נחליט שמדובר ב-2. אוקיי? זה התהליך בעצם של הזיהוי אוקיי? זה ככה דוגמה לתהליך של הזיהוי ועכשיו נחבר את זה רגע למערכת IR אוקיי? אז מערכת IR איך עשינו את זה בעצם? יש לנו בעצם שתי גישות שהיו נהוגות ו... השימוש היה בעיקרון ב-HMM ו... בואו ניתן את הדוגמה הזאת כאן אז נגיד שמסמך ראשון זה שתי מסמכים של Voice. המשתמש אמר Global Warming ונגיד שה-HMM זיהה את זה נכון? במסמך השני במסמך בקובץ השני המשתמש אמר Climate Change נגיד, וה-HMM לא זיהה את זה, נכון? הוא זיהה את זה כ-Climate Change במקום Climate Change אוקיי? זה... די קרוב אנחנו רואים למילה זה לא שהוא טעה בעליל אבל הוא לא פיינח בצורה מדויקת אוקיי? אז הפתרון הפשוט לוקח את ה-HMM שמוצא מקסימיזציה לכל שלב ו... זה מה שהוא החליט שהמסמכים אומרים ועכשיו אם אנחנו מחפשים לצורך העניין Climate אוקיי? אז אנחנו לא נמצא את המסמך השני. 

למה? כי אנחנו מחפשים ככה התאמה מדויקת של התהליך של ה-HMM שעשה מקסימיזציה אוקיי? הפתרון אגב שאנחנו נראה הוא מאוד פשוט ומאוד דומה למה שראינו בעיבוד תמונה אם אתם זוכרים מה עשינו בעיבוד תמונה? איך זיהינו באוסייר אני מתכוון איך... שם אמרנו שהיו אותיות שטעינו בזיהוי אז איך פתרנו את הבעיה הזאת? במקום לנסות לזהות מילה ניסינו לזהות N גרם של אותיות Q גרם סקר אחוז אוקיי? אז נעשה משהו דומה גם פה בעצם כן? הפתרון הזה לא כל כך טוב כן היה אפשר לבוא ולשפר את הפתרון הקודם ולהגיד אל תשמעו רק את האופציה הטובה ביותר אלא תשמעו גם את האופציות הפחות טובות ואז הם פשוט יקבלו ציון נמוך יותר. אז נגיד אם כאן שמענו גם את קליימנט שקיבל רק הסתברות נמוכה יותר של 0.45 אז נקבל אותה גם בתור פתרון רק עם סיכוי עם התאמה נמוכה יותר. אוקיי? אז כאן אנחנו רואים את כל המילים שהוא שמר את ההסתברות והסיכוי בגלל ההתאמה להגיע לכל אחת מהמילים איזושהי הדמייה של כאילו, מה אנחנו רואים מבחינת המכונה ועוד שיפור נוסף שהיה מקובל לעשות זה שיהיה יכולת לטפל במילים מה שנקרא, אגב גם היום יש את זה בעיה באללמים כשה מוקאבולרי מוגבל היום הוא מוגבל הרבה פחות אבל הוא עדיין לא מכיר את כל האפשרויות נותנים גם אפשרות לסווג עברות או יצורים כמו שרואים פה בכל מקרה הפתרון נקפוץ לשם הפתרון נראה שלא קפסנו עדיין לשם, אז לפני זה נוסיף עוד משהו שהיה אפשר להציג את זה אגב בכל מיני מובנים גם בחיפוש הכי פשוט שהיה לנו קודם מה שאני מתכוון זה לשלב חיפוש בטקסט וכל מיני יסדות מובנים נגיד שאנחנו רוצים לחפש מישהו שאמר דבר מסוים אבל רק בשכבת גיל מסוים וזה שמור לנו בדטאבס אז נוכל לשלב את הדטאבס בתור איזשהו פילטר, נגיד הוא נמצא מעל גיל 18 מתחת לגיל מסוים עכשיו אם הוא אמר, הוא הראה לנו תעודת זהות נגיד, ועכשיו אם אוטומטית הוא אמר למיקרופון שלנו נגיד אני רוצה לקנות אלכוהול, אז אם הוא הראה תעודת זהות והוא עדיין קטין אז לא ניתנו אלכוהול למשל אז באותו אופן כאן אנחנו מהנדקסים גם את הארטפוט של האם זה זכה או נקבה וזה יהיה בשלב הראשון בוליאני hard constraint ואז ניקח את המילים של מה שחיפשו רצו נגיד דוברת שאמרה ככה וככה, תחשבו שנגיד אנחנו עושים חקר של שירים ומעניין אותנו רק הזמרות למשל או המשוררות אז יכול להיות שיש תכונה מסוימת שאנחנו מחפשים אבל היא מלל מסוים, אז שילוב במשהו שהוא יותר מובנה למרות שפה זיהינו בכלל שמדובר באישה ולא באיש התהליך לא כל כך פשוט אז הנה דוגמה למונחים שאנחנו עושים להם inverse indexing נגיד לwarming, וקיבלנו שני מסמכים שבהם הייתה המילה warming וראינו שלושה מסמכים שהתהליך שלנו זיהה אותם בתור נשים אז עכשיו אם נחפש warming לנשים נקבל את 0-3, זה החיתוך ביניהם זה דומה קצת לבוליאן search שהיה לנו בהתחלת הקורסים אתם זוכרים אז זה ככה הוויזואליזציה של התהליך הזה יש לנו מילים שמכילות את המילה warming וגם מזורות כנשים אז אומנם לנשים יש גם את מסמך 4 ולא מכילים את warming אז זה היה חיתוך בין שניה עכשיו עוד משהו שהיה אפשר לעשות גם במנועי חיפוש כמו לוסין למי שמכיר מאוד מקובלים זה מה שנקרא faceted search שזה במקום לפלטר הוא פשוט נותן לנו את כל האפשרויות נגיד המידע המובנה שיש לנו עבור תוצאות חיפוש מסוימות למשל הוא אומר לנו עבור המסמכים שהוא מצא כמה סחרים יש וכמה נקבות נגיד שכאן חיפשות גלובל אז הוא אומר לנו שיש לנו מסמך 0 אם אתם רואים מכיל את המילה וגם מסמך 2 מכיל את גלובל אז הוא אומר לנו שנמצאו שני מסמכים אחד לגבר ואחד לאישה, כן? זה מה שנקרא faceted search אבל אם למשל עכשיו ככה ננסה להתאים את זה לתהליך שעברנו עם הטקסט מבוליאנס לתהליך שהוא יותר הסתברותי אז כאן יש לנו דוגמה לחיפוש שהוא לא סטריק כמו בוליאנס זה אותו דבר כמו שאפשרנו בחיפוש רק של טקסט שהוא פחות סטריקט הוא לא בוליאני, הוא לא הכל או כלום אז אפילו חשוב יותר כאשר אנחנו מדברים על יכולת שהיא לא פשוטה להשגה ויכול להיות שלא השגנו את זה בוודאות מקסימלית נגיד הזיהוי מדובר בנשים או גברים זה היה אאוטפוט של אלגוריתם ציבור אלגוריתם קלסיפיקציה אוקיי אז במקום להציג האם מדובר בזכה או נקבה ולתת רק את הנקבות נגיד שביקשו מסמכים שמכילים את המילה גלובל של נשים אז פשוט נתנו בוסטינג פקטור אם מדובר באישה כל מי שמכיר למידת מכונה יודע שהיום לא עושים את זה ככה אז למרות שהשתמשו ברכיבים פנימיים של למידת מכונה כמו לזאת אם מדובר באישה או איש או אפילו הHMM הזה שזה גם נחשב למידת מכונה אבל השילוב של כל מיני רכיבים עדיין היה קצת רולבייס כזה ככה היו עושים איזה פעם אגב זה לא עבד מהעולם למרות האלה למים יש כל מיני סנאריו שעדיין נצטרך להשתמש בדברים האלו אז פשוט במקום זה מה שהוחלט כאן זה לתת בוסטינג פקטור לאישה כדי שהיא תקבל תוצאה גבוהה יותר אבל לא לפטר לגמרי את התאמה על הגבר אוקיי אז פשוט קיבל ציון עמוך יותר אוקיי אז לבסוף הדבר האחרון שאני רוצה להראות זה שתי דוגמאות ככה של שילוב של סיגנלים שונים אז דוגמה ראשונה התשלב טקסט עם אודיו ודוגמה שנייה תעשית גם תמונה שיהיה עוד יותר שמח אפילו אוקיי וככה זה עוטף את כל הדברים, הסיגנלים השונים שדיברנו עליהם שהם לא מכילים רק טקסט פשוט אוקיי זה האוטפוטים השונים שדיברנו עליהם אוקיי אז יש לנו פה שני מסמכים אחד שכולל את מסמך טקסטואלי שכולל את המילה weather מה זה גביר weather והמסמך השני זה מישהו שאמר weather אבל זה נשמע על ידי המנוע של Speech Recognition כ weather משהו כזה אוקיי אם אתם רואים פה את המילים שהוזיעה כלומר הייתה טעות פונטית מסוימת שהוזיעה את ה-TH כ-DH לצורך העניין אוקיי אז הדרך שבה כדאי לנו להתנהג זה דומה קצת לדרך שהיה לנו בזיהוי של באו-CR של האותיות זה להנדקס פונמות כאן אוקיי אז נעשית אותו תהליך גם לטקסט וגם לאודיו כדי שנוכל לחפש אחרי אותו פרוססינג שאילתה נוכל לחפש את זה גם במסמכים של האודיו וגם במסמכים של הטקסט אוקיי אז אנחנו נחלק את זה באותה צורה בצורה פונטית אז נגיד שבראשון במסמך טקסט כתוב project alpha deadline friday ובקובץ של השם אז נאמר urgent call me project alpha נגיד שזה מה שנאמר ועכשיו לצורך העניין אז שוב יש לנו פה זיהוי לא נכון שנגיד במסמך הקובץ אודיו P נהפך ל-B אוקיי ושאילתה לצורך העניין נגיד ששאלו ביקשו את project alpha אוקיי אז קודם כל אנחנו נהנדקס פה שלושות גם לצורך העניין נגיד אבל הפעם במקום סתם אותיות זה שלושות פונטיות של פונמות אוקיי אז היוזר לצורך העניין אמרנו שהוא חיפש project alpha אז כאן הוא ימצא גם את מסמך א' וגם את מסמך ב' בגלל אותו אינדוק של שלושות של פונמות בגלל שיש התאמה פחות טובה במסמך ב' כי היה פה כמה פעויות בזיהוי אז הוא מקבל ציון ציון יותר נמוך אבל הוא עדיין חוזר אוקיי רואים כאן שהוא קיבל 0.21 לעומת 0.55 שהטקסט פייל קיבל, הכל בגלל הטעויות שה automatic speech recognition זיהה לו נכון חלק מה פונמות אוקיי ואם נעשה ויזואליזציות להתאמות של השלשות האלו איפה שיש ירוק במסמך טקסט אנחנו רואים שהיו הרבה התאמות ופחות התאמות במסמך של האודיו אגב חלק מאותם חוסר התאמות אגב יש פה חוסר התאמה אחת במסמך טקסט בגלל שהשאילת הייתה גם בבויס אז הוא שוב זיהה פרוג'ק לא יודע מה, פרוג'קט או משהו כזה פי במקום פי ולכן הוא לא התאים לטרייגרם אפונמי של אפונמות של הטקסט דווקא אבל כל שאחר השלשות אפונמיות זהו נכון אבל היה פחות התאמות ב קול של האודיו של השם, בקובץ של השם אחת מאותם התאמות זה דווקא הייתה התאות בזיהוי של השלשה של התחלה של המילה של פרוג'קט כאן אגב מה שמראה זה קשור לפרקטיקה אלגוריתמית באופן כללי לא רק ללמידת מכונה גם אבל באופן כללי שאם עושים טעות עדיף שהיא תהיה טעות קונסיסטנטית אז כאילו אם תמיד המנוע של ACR Automatic Speech Recognition מזהה את הפרו כברו אז לא נורא כי זה טעות קונסיסטנטית זה מתאמן עליה נדע למצוא אותה גם בקובץ שם אוקיי? לעומת זאת בקובץ טקסט לא מצאנו זה לא פתרון מושלם אבל יש לזה ערך אם זה קונסיסטנטי אוקיי אז זה ככה סיכום של מה שעשינו ודוגמה אחרונה שאנחנו נביא זה שנוסיף גם תמונות ואז נסיים להיום אז כאן יש לנו גם טקסט גם אודיו וגם אימג' בתור שלוש סיגנלים שונים זה יכול להיות קובץ אחד עם רכיבים שונים של מולטימדיה או כמה קבצים אוקיי? אז כאן יש לנו בדוק A בכל אחד מהם כאן בסנריו הזה יש לנו את שלושת הסיגנלים בכל אחד מהקבצים אז בדוק A שהוא מסוג פישינג בלוג כתוב לנו אז הטקסט זה קוטי ג'יינט בס האודיו זה קול של מים משפריצים והאודיו זה תמונה של דג בקובץ השני זה קלאב מוזיק הטקסט זה דרופ הביט והאודיו זה אלקטרוניק סאב בס והאודיו זה אורות של ניאון האחרון האחרון זה ג'אז קונסרט הטקסט זה בס פלייר גיטרה בס פלאקט סטרינג והאודיו זה אקוסטיק לואו נוט והוויזיול זה איזשהו רודן אינסטרומט זה כנראה גיטרה בס אז עכשיו מה ש יש לנו בעיה עכשיו זה זיהוי של המילה בס למה הכוונה אם הכוונה היא לדג בס לכלי הנגינה או לטדר בס יש לזה רב משמעות ואנחנו פשוט ניתן לזה ניקוד על ידי מה שנקרא פיוז'ן של כל הדברים שזה אומר סוג של קומבינציה ליניארית של ההתאמה לאודיו לטקסט ולאימץ' אוקיי? אגב זה דרך שהיא לא אופטימלית זה לא הדרך שבה זה נעשה היום הדרך האופטימלית זה להתייחס לכל כחלק מאותו קונטקסט ולהבין אם זה קשור או לא קשור לא סתם קצר אז השעילת הייתה רק בס לצורך העניין אה לא השעילת הייתה שנייה עוד רגע נראה לא לא השעילת הייתה איפה השעילת הכוונה הייתה לדאג בס אני מנסה לחפש בדיוק את המילים של השעילת יכול להיות שלא כתבתי זה אה נכון נכון היוזר קווי קרא גם כמה סיגנלים גם את הבס ואז הוא אמר משהו כמו כזה כן והתמונה שהוא נתן זה איזשהו טקסטורה של עץ כזה חום עץ בצבע חום אוקיי וכתוב לנו שהכוונה שלו הייתה בקלין נגינה של גיטרה בס ולא דאג אוקיי אז כאן הזכרנו את זה קודם על הכלוריסטגרם אני מראה את זה כאן כי זה הפיצ'ר אקסטרקשן שעשו פה יש פה אדום ירוק וכחול את ההיסטוגרמות של שלושתן אז בעצם זה השרשור של זה או בגרסות מסוימות חיבור בין שלושתן זה מה שנותן לנו את הפיצ'ר וקסטור מהתמונה לצורכניה אז כאן יש לנו את שלושת המסמכים ואת האטמות שאנחנו רואים שהאטמה כוללת את שלושת האטמות האחרות אוקיי אז יש לנו במסמך A הייתי צריך להדביק את המסמך ליד כאן כדי שזה יהיה ברור מסמך A זה היה דאג בס אוקיי אז מסמך A אהה כתוב פה פישינג בסדר, הייתה אטמה מסוימת של אהה 0.19 בערך לבחינת הטקסט אטמה נמוכה יותר לאודיו של 0.1 והאטמה בינונית נגיד אהה אהה תמונה אוקיי מבחינת הקלאב מיוזיק אפס אחוז האטמה לטקסט כי כאן כתוב בכלל ביט זה לא בס הייתה אטמה מסוימת בגלל שה אהה עשינו חלוקה כנראה של פונמות אז זה