או מתייחס לקונטקסט, וממנו על ידי המטריצות של Q, K ו-V, שאותן אנחנו לומדים, אנחנו בעצם משיגים את הקונטקסט של World Embeddings. אוקיי? אז זה בעצם הנוסחה של ה-Self-Attention שנפרק ונסביר. אז יש לנו רכיב של Softmax, שאחרי זה נסביר קצת מה הוא עושה, וכאן אנחנו עושים מכפלות של Q כפול K, אוקיי? מנרמלים את זה בשורש של DK, ובסוף מכפילים את זה ב-Value.

אז מה זה כל הדבר הזה? אז קודם כל מבחינה ארכיטקטורית זה נראה ככה. לצורך העניין יש לנו כאן משפט שכתוב, John recently bought an apple mobile. אוקיי? אז יש לנו פה לצורך העניין חמש מילים באינפוט, ובשלב הראשון אנחנו הופכים את החמש מילים האלו לאמבדינג סמנטי.

אוקיי? זה ה-E שאנחנו רואים כאן. זה לא ה-John עצמו, אלא האמבדינג של John, האמבדינג של Recently, האמבדינג של Bought, האמבדינג של Apple והאמבדינג של Mobile. אוקיי? ואז את הדבר הזה אנחנו מעבירים, אנחנו כמובן לומדים את זה דרך ה-Weight Matrix של Q ושל K. ה-Q זה ה-Query וה-K זה ה-Key.

אוקיי? אנחנו מפעילים על זה את המניפולציה של ה-Softmax, ובסוף אנחנו מכפילים את זה ב-Value. אוקיי? אז מה שאנחנו מקבלים בסוף, שוב עדיין לא הסברנו, אבל כאן אמרנו שיש לנו World Input, כאילו World Sequence Input נגיד, ואז אחרי שלב אחד אנחנו עושים מה שנקרא Semantic Embedding, שזה תהליך דומה למה שה-World2Vec עושה. הוא מייצר לנו Semantic Embedding, אבל הוא לא תלוי הקשר.

ואז בהינתן שלמדנו כבר את ה-Weight של Q, של K ושל V, בסוף בסוף אנחנו מקבלים את ה... נקרא לזה במקום E, נקרא לזה CE, זה ה-Contextual Embedding של כל אחד מהמילים האלו. אוקיי? אז לצורך העניין, השלב הראשון הוא ה-Embedding, והשלב האחרון זה ה-Contextual Embedding. זה בעצם ה-Output של התהליך הזה, וכמובן שכל אחד מאלו יכול להיות שונה מכל אחד מה-Outputים האלו, כי הוא בעצם מכניס גם את ה-Context ולא רק את ה-Context, את המשמעות הסטטית של כל אחד מהמילים.

משמעות הסטטית בעצם מתעלמת מההקשר שהופיע במשפט, אלא רק מתייחסת לנגיד ההקשר המסתבר ביותר מבחינה הסתברותית, שלמדנו בכבצים השונים ולא על ההקשר הנוכחי. אז לצורך העניין, בואו נגיד שיש לנו איזשהו משפט כזה, A fluffy blue creature roamed the verdant forest. אוקיי? אז מה היינו רוצים להבין לגבי היצור הזה כאן שמופיע כאן? אז יש לנו פה הרבה ויזואליזציות בתקווה שזה יעזור קצת להבין.

בסוף היינו רוצים, נגיד אם ניקח את הקריטשר, אז נגיד שיש לנו איזשהו Embedding שבאינפוט הסטטי הוא מציג אותו בצורה הזאת. כן? זה סתם ויזואליזציה, כן? אז זה כאילו המשמעות הסמנטית של קריטשר. אבל אנחנו רוצים שזה לא יהיה סתם קריטשר, שזה יהיה לנו fluffy blue creature.

אז בעצם אנחנו רוצים שהמנגנון של ה-Attention ילמד שיש לנו כל מיני מילים שהם רלוונטיות מילים שנאמרו קודם שהם רלוונטיות שיהפכו בעצם את הדבר הזה לדבר הזה בסוף. אוקיי? יש לנו blue ויש לנו fluffy. אוקיי? אם נרצה בצורה מאוד שטחית ופשוטה נגיד שיש לנו פה adjectives תארי השם ויש לנו פה איזשהו שם עצם ואז אם אנחנו מצרפים בצורה שטחית את ה-Adjectives לשם עצם אנחנו מקבלים כבר איזה משהו מורכב יותר.

אז זה נותן לנו כבר משמעות של הקשר. אוקיי? ובאותו אופן יש לנו פה יר. אני לא יודע כמה רואים פה את ה-verdant forest.

אז יש לנו פה את היר ואת ה-verdant forest שנראה כבר אחרת. אוקיי? זה מה שהיינו רוצים שילמד מהcontextual embedding. זה הרעיון? אוקיי? אז בעצם עוד המחשה ככה למה בעצם המשמעות של ה-Q ושל ה-K.

אז בעצם המחשה כאילו מאוד... כאילו ה-Q שואל שאילת את שאר המילים במשפט. הוא אומר, יש לי פה איזשהו noun, שזה הקריצ'ר שלנו נגיד. אוקיי? האם יש איזה שהם מילים בקונטקסט שלנו שיכולות לעזור לי, אולי adjectives זה משהו שיכולות לעזור לי ולתת משמעות לפי ההקשר? זה כאילו השאלה שהוא שואל בצורה שטחית, כן? הוא אומר, יש לנו את ה-noun-creature.

האם המשמעות שלי משתנה בגלל ההקשר, המילים בהקשר? ואז יש לנו את ה-Q שעונה בעצם על השאלה של ה-query. וה-Q אומר, כן, יש לנו משמעות של fluffy ושל blue, שמשנות את ההקשר שלך. אז איך זה בעצם מתבצע, הקשר הזה בין ה-Q שהוא שואל את השאלה, איזה מילים בקונטקסט רלוונטיות בשבילי לשינוי? וה-K שעונה על השאלה הזאת ונותן את המשמעות של המילים בקונטקסט.

אז השיטה שבה עושים את זה זה על ידי dot product, בין זה לבין זה, שזה נותן את המשמעות המורכבת של הקונטקסט. אוקיי? אז כאן יש לנו בעצם מחפלה ויקטורית של ה-Q של כל אחד מהם, ושל ה-K של כל אחד מהם, שבעצם נותנת לנו בתשובה איזשהו attention score, אוקיי? יש לנו תשובה לכל אחד מהם, והיא בעצם מתבטאת בצורה הזאת אחרי שעשינו dot product, היא אומרת, נגיד, שהציון שמקבל ה-fluffy עבור המילה creature הוא 93, והציון שה-blue מקבל עבור ה-creature הוא גם 93.4, זה ציונים גבוהים, ויש לנו פה כל מיני ציונים, שהם אפילו שליליים, ואחרי זה אולי נשתח אותם ל-0, והם פשוט לא ילקחו בחשבון. כלומר, הטוקנים האחרים, אנחנו לא רוצים לתת להם את ה-attention, הם לא ישפיעו לנו על הקונטקסט.

אז זה הרעיון כאן, ואם נעשה לזה איזו הדמיה של ויקטורית, אז אנחנו אומרים שה-creature ועוד משמעויות של blue, נגיד, ו-fluffy, זה נותן לנו את אותו יצור שיצרנו, עם החיבור של הקונטקסט ל-creature כאן. אוקיי? אז זה בעצם החיבור של הכל ביחד, זה האחריות של ה-value. אז נעשה איזה חזרתיות כאן בשביל ליישר קו, אנחנו מדברים מהמנגנון של הטרנספורמר, שמשלב q, k ו-v, q זה ה-query, k זה ה-key ו-v זה ה-value.

אוקיי? ובעצם ה-q שואל איזה מילים בקונטקסט יכולות לתת לי משמעות אחרת, יכולות באמת להיות רלוונטית למשמעות שלי, זה מה שה-q שואל. ה-k בעצם נותן לנו את המשמעות, זה בעצם עונה ל-q, ואנחנו עושים את הדבר הזה על ידי dot product שלהם, אוקיי? ובסוף מי שמאגד את הכל ביחד זה ה-value, אנחנו עושים את זה על ידי הכפלה של ה-value ב-attention score, שה-attention score זה בעצם ההכפלה הוקטורית הקודמת שעשינו, ואז יש לנו את ה-context embedding. אז זה התהליך בגדול.

עכשיו נרד קצת לשלבים, איך עושים את הדבר הזה? אז אנחנו מתחילים מזה, כמו שאמרנו, שאנחנו רוצים קודם כל לפרק את המשפט. אז יש לנו ווקאבלרי שהוא מוגבל לגודל מסוים, נגיד ווקאבלרי של gpt, אם אני זוכר נכון, היה בערך 50 אלף מילים, אוקיי? ואז אמרנו שהמילה, כל מילה בעצם אמורה להיות תלויה במילים הקודמות לה, אוקיי? אז בעצם יש לנו תווים מיוחדים שמסמנים לנו את התחלת המשפט, זה במודלים דומים למודל של ברט, אז יש לנו פה את ה-SOS, זה start of a sentence, כאילו את התחלת המשפט, ו-EOS זה end of a sentence, סוף המשפט, אוקיי? ובגלל שאנחנו רוצים לעבוד במכפלה וקטורית, אז בעצם אנחנו רוצים שיהיה לנו פה אינפוט שהוא בגודל קבוע, אבל מה לעשות שלא כל המשפטים שיהיו לנו בגודל קבוע? אז הפתרון הפשוט שעושים לדבר הזה, זה המציאו עוד איזושהי מילה פקטיבית, שהיא בעצם בדומה לאפסים ששמים מסביב לתמונה, כשעושים מכפלה בקונוולוציה, אז כאן בעצם מוסיפים מילה שהמשמעות שלה היא כזה placeholder מילה ריקה כזאת, אוקיי? padding של מילים, אוקיי? אנחנו רואים שפה ב-Vector המילים הריקות האלו מקבלות לנו בעצם אינדקס של 0, כן? התחלת המשפט זה אינדקס של 1, זה הכל, כל הדברים האלה הם שמורים ולא משתנים, לא משנה מה המילים האחרות, אז ה-0, 1 ו-2 זה מילים קבועות של padding של התחלת משפט ושל סוף משפט, אוקיי? יש עוד מילים קבועות נוספות, אבל זה העיקר וזה בעצם הרחבה של התהליך של ה-Tokenization, אז התהליך של ה-Tokenization בעצם כולל חלוקה של המשפט למילים, לפעמים גם לתתי מילים, לחלקים שיש להם משמעות בשפה, לפעמים שהן פחות ממילה יש לזה גם משמעות, אבל לצורך היה נגיד לטוקנים למילים, דיברנו כבר על הטוקנים, אבל מוסיפים גם את היחידות הנוספות האלו של התחלת וסוף משפט ושל הפאדינג, כדי שבעצם כל המשפטים יהיו באותו אורך, אוקיי? ואז אפשר בקלות לעשות את אותו כפל וקטורי, ואת הדבר הזה בעצם אנחנו מכניסים, יש לנו איזשהו Embedding Static, Semantic Static, אבל בלי קונטקסט, כן, אז את הדבר הזה אנחנו מכניסים כ-input, לכל מודל שפה יש את ה-tokenizer שלו, עם כל מיני מילים שמורות כאלו לטוקנים, ועם דרך מסוימת האם הוא שובר מילה או תתי מילים, וכל מיני דברים כאלו, יש כאלה שלמשל בכלל מחפשים גם ביטויים, יחידות יותר גדולות מאשר מילה, אוקיי? זה לפעמים גם תלוי שפה, ואת הדבר הזה אנחנו יוצרים לכל אחד מהיחידות הבסיסיות של הטוקנים האלו, אנחנו יוצרים את אותו Embedding Static, אז זה התחלת התהליך, אוקיי? אז מה קורה בשלב הבא? אז בשלב הבא יש לנו את האימון של ה-q, כאן יש לנו דוגמה דווקא בהינדית, יש לנו את האימון של ה-q ושל ה-k, אוקיי? מכפילים את ה-q ואת ה-k, ובעצם שואלים את השאלות שאמרנו, אוקיי? אנחנו שואלים, בהינתן המילה הקודמת, מה הסיכוי שנראה את המילה הנוכחית? אוקיי? אז כשאנחנו למשל עושים תרגום בין שפות, אז יש מנגנון שנקרא Cross-Attention, אוקיי? בעצם השפות השונות הם לא בהכרח זהות, כן? זה לא שיש לנו אנגלית ואנגלית או הינדית והינדית, זה יכול להיות נגיד מהנגלית להינדית, ואז בעצם יש לנו רק את המילה הראשונה שהיא זהה, שזה הסימון המיוחד להתחלת המשפט, ומפה ועלה יש לנו את המילה הראשונה, נגיד, ששפת המקור היא אנגלית, אז אנחנו שואלים בעצם בתהליך הזה של ההכפלה הוקטורית, אנחנו גם עושים את התרגום משפה לשפה, אז הנה השלבים הראשונים של איך היינו עושים כשיש לנו כל וקטור מיוצג על ידי שני מימדים, כל מילה מיוצגת על ידי שני מימדים, אז לצורך העניין יש לנו פה את ה-query, key ו-value של ה-token A, ואת ה-query, key ו-value של ה-token B, אז מה שאנחנו שואלים, מה שאנחנו רוצים שיהיה לנו אחרי המכפלה של A ו-B, של ה-query של A ו-B ב-key של A ו-B, זה נותן לנו דבר כזה, בעצם אנחנו שואלים מה אנחנו יכולים לדעת לגבי המילה A מתוך הקונטקסט, ובעצם ה-key של A אומר שמה-A עצמו אנחנו יכולים לדעת כמות כזאת של מידע, אבל גם חלק מהמידע זה לדעת מילים מ-B, אז גם A על עצמו יכול להיות שהוא יהיה משמעותי יותר או משמעותי פחות, זה תלוי במילה ובחשיבות של הקונטקסט לעומת המילה, יש מילים שהקונטקסט בקושי משביע אליהם, ויש מילים שהם עצמם מאוד משתנים ביחס לקונטקסט, ואותו דבר לגבי המילה B, המילה A יכולה להיות משמעותית נגיד ב-20% למילה B, ו-B יכולה להיות ב-80% לעצמה. אוקיי, אז זה בעצם מה שאנחנו מקבלים, הדבר הזה זה בעצם יוצר לנו איזשהו attention score, כמה הקונטקסט משפיע לנו על המילים עצמם, בהכפלה של key וה-query.

אוקיי, אנחנו עושים dot product מהסוג הזה, Q כפול K transpose, בעצם את ה-K אנחנו הופכים לווקטורים של עמודות. אוקיי, וה-K עונה כביכול ל-query, כאן יש לנו קונטקסט של חמש מילים, הקונטקסט בעיקרון הוא בגודל זהה תמיד, מכיוון שבעצם אנחנו מייצגים פה תמיד את אותו קונטקסט עם אותם תווים מיוחדים של padding שאמרנו שאנחנו מוסיפים. אוקיי, אבל נניח כרגע שיש לנו חמש tokens, חמישה tokens, אז אנחנו מכפילים וקטור של, או מטריצה של ה-query יחד עם ה-Key, נוצרת לנו כאן מטריצה, יש לנו כמה כל אחד מה-tokens משפיע על כל אחד מה-tokens האחרים.

אוקיי, ואז בעצם שאלנו כמה כל אחד מהם משפיע, זה בעצם מה שאנחנו שואלים, נגיד שכאן יש לנו את המשפט Apple released a new iPhone model last week, ואנחנו שואלים כמה כל אחד מהם בעצם משפיע על כל אחד מהמילים האחרות, זה מה שאנחנו עוד דיברנו. אוקיי, אז אנחנו רואים למשל שאפל מאוד השפיע על האייפון, כאן יש לנו ויזואליזציה שמראה לנו לפי האובי של המשקולת, בעצם כמה השפעה יש לנו לפי האובי של הקשת, בעצם כמה חשיבות יש לנו עבור כל מילה לכל מילה אחרת בקונטקסט. אוקיי, אז נגיד אפל מאוד השפיע על אייפון, והשפיע גם בצורה די משמעותית על מודל, אבל היא לא השפיעה על מילים כמו A כמעט בכלל, וגם על last week לא כל כך השפיעה, כמובן שהיא די השפיעה על עצמה גם, אוקיי, אז זה כל מיני מילים, בעצם זה המילים שהשפיעו על אפל, הפוך, אמרתי בדיוק את ההפך, זה כל המילים שאנחנו אומרים כמה הם השפיעו, זה התשובה לשאלה על אפל, איזה מילים משפיעות על אפל, אז זה בעצם משמעות, האייפון היא מאוד משמעותית לאפל, המודל הוא מאוד משמעותי לאפל, אפל גם משמעותי לעצמו, גם הרליסים השונים שהם עושים בטקסט המיוחד של אפל, אבל מילים כמו A, New וLast Week לא השפיעו על אפל, אוקיי, אז זה הפוך ממה שאמרתי, הכי בא לענות על הקווירים.

אוקיי, ובסוף בסוף אנחנו נותנים בעזרת ה-Value ממש אחוזים של כמה כל אחד מהם השפיע, ובעצם אנחנו יוצרים מתוך הדבר הזה קומבינציה כזאת של ה-Embeddings שהתחלנו איתם, ויוצרים ככה את ה-Contextual World Embedding האחרים. כן, אז בעצם אנחנו במנגנון של ה-Attention מתחילים מאמבדינגס, ואנחנו נותנים תיעדוף מיוחד למילים שמשמעותיות בהבנה של המילה שלנו מתוך הקונטקסט, ולא נותנים לכל הקונטקסט חשיבות זהה. אוקיי, יש מילים שמעלות משמעות מסוימת, מורידות משמעות מסוימת, זה בעצם מה שאנחנו עושים עם ה-K, Q וה-V שלנו כאן.

עוד פרט שחשוב לדעת זה שכל מה שאמרנו עד עכשיו יתייחס לקונטקסט, אבל לא יתייחס למיקום של מילה בתוך הקונטקסט. אז בשביל זה ייצרו בהתחלה Positional Encoding Static, ועכשיו גם אותו מאמנים, אבל הצורה והשיטה שבה התמודדו עם הדבר הזה זה עם גלים של סינוס ושל קוסינוס. ואמרו דבר כזה, בואו נחלק את זה לאינדקסים חיוביים ושליליים.

לאינדקס ה... אם אני לא טועה, החיובי... סליחה, זוגי ואיזוגי, לא חיובי ושלילי. לאינדקס הזוגי אנחנו ניתן ערך של קוסינוס, ולאינדקס האיזוגי ניתן ערך של סינוס. אם אני לא טועה זה היה ככה.

אוקיי, אז בעצם לסירוגים אינדקס 0, 2, 4 וכולי, מקבלים את הערך של הקוסינוס, ובהתאמה אותו דבר לגבי הסינוס 1, 3 וכולי. וככה בעצם את הדבר הזה עושים באותה מימדיות כמו המימדיות של האמבדינג הרגיל, אז בעצם זה משנה קצת את הערכים של כל אחד מהאמבדינג, וזה הדרך שעבדה בצורה לא הוראה למרות שהיא סטטית, במאמר המקורי של המנגנון של הטרנספורמר של ה-attention. ובעצם קודדנו ככה גם את האמבדינג המקורי, גם את ה-positional encoding, בעזרת הגלים האלה של הסינוס והקוסינוס על המקומים בתוך המשפט, ובעזרת ה-U, K ו-V, אז בעצם אנחנו שומרים גם על ה-contextual embedding, אנחנו מכניסים פה גם את הקונטקסט, איך הוא משפיע על המשמעות.

עכשיו עוד הבחנה קטנה שהזכרנו אותה, בעצם יש לנו שתי סוגים של attentionים, ה-attention אחד זה מדבר על מקרים שיש לנו את אותה שפה באינפוט ובאוטפוט, וה-attention שני שבעצם אם נרצה הוא לומד זוגות זוגות של אינפוט ואוטפוטים, והוא יאפשר לנו בעצם באותה מכפלה גם להמיר כבר לשפה אחרת. אז זו דוגמה קלאסית לשימוש ב-attention בשביל machine translation, בשביל תרגום שפות. המקרה הזה זה אם אני לא טועם באנגלית לצרפתית.

אז דיברנו על מנגנון-attention שבעצם אכיל כמה רכיבים, רכיב ראשון היה לנו את ה-embedding הסמנטי הסטאטי, ה-positional encoding, דיברנו גם עוד לפני זה על ה-tokenization המיוחד, ודיברנו גם, אז נכתוב את זה לראות שאני לא מפספס כלום, אז דיברנו על ה-embedding הסמנטי הסטאטי, עוד לפני זה על ה-tokenizer המיוחד שאמור להיות מתאים לכל אחד מהמודלי שפה, יש לו את ה-tokenizer המיוחד שלו, שמעבר להחלטה אנחנו עובדים ביחידה שהיא subword, subword world of race, זה נראה לי שלושת האופציות המרכזיות, אז מעבר להחלטה הזאת יש לנו כל מיני תווים מיוחדים, שבכל אחד מהמודלים השונים נראים קצת אחרת, אז כאן נגיד במודל הזה של BERT יש לנו ככה התחלה של משפט, או סוף המשפט הקודם, יש לנו גם separator כזה, קודם ראינו תווים מיוחדים של לדעתי במודלים של BERT אם אני לא טועם משמשים, SOS ו-EOS של התחלה וסוף משפט, והיה לנו גם padding בשביל להוסיף עבור מילים ריקות, אז כאן אנחנו רואים נגיד MY DOG IS CUTE יש לנו הפרדה בין משפטים, אז יש לנו תווית מיוחדת של separator בין משפטים בתוקניזר שהדפולטיבי כנראה של BERT, ודיברנו קודם על תוקניזר של חלק מהמילה, אז אנחנו רואים פה בתוקניזר של BERT בסאבוורד תוקניזר, שהוא חילק את המילה המקורית PLAYING ל-PLAY עם סיומת ING, אז זה התוקניזר של BERT עושה, ואז אנחנו עובדים עם הטוקן EMBEDDING, אנחנו בעצם, יש לנו טוקן סטטי לכל אחד מהטוקנז האלה אחרי שלב הטוקניזר, ואנחנו מוסיפים חלוקה למשפטים שונים שיהיה לנו את הקונטקסט המתאים לכל אחד מהם, ואחרי זה אנחנו מוסיפים POSITIONAL EMBEDDING, אחרי שאנחנו מוסיפים את ה-POSITIONAL EMBEDDING, את המיקום של כל מילה לפי הגלים של הסינוס והקוסינוס שעליהם דיברנו קודם, אנחנו בעצם באימון, אנחנו מאמנים את ה-WEIGHT של ה-Q, K ו-V, שבעצם שואלים, ה-Q שואל, כמה כל מילים בקונטקסט בעצם משפיעים עליי, על המילה של השאלה, וה-K אחריי בעצם כאילו לענות על השאלה הזאת. בשביל ללמוד אספקטים שונים של השפה, אז בעצם לא עושים את הדבר הזה פעם אחת, לא עושים את ה-ATTENTION פעם אחת, אלא עושים מה שנקרא MULTIHEAD ATTENTION, מחלקים את הוקטור הגדול לתתי חלקים, ולומדים בעצם את התהליך הזה כמה פעמים, כך שמכריחים בעצם כל אחד מה-MULTIHEAD ATTENTION, כל אחד מה-HEADים האלו, מכריחים אותם בעצם ללמוד אספקט אחר של המילים, והקשרים מסוג שונה, ואז מחברים את הכל ביחד לייצר וקטור אחד. אוקיי, אז זה ה-K, V, סליחה, ה-Q, K ו-V לומדים את ה-CONTEXTUAL EMBEDDING, אבל בגלל שחוזרים על זה כמה פעמים, אז אנחנו לומדים כאילו את ה-EMBEDDING מנקודות מבט שונות.

אוקיי, אז יש לנו עוד מנגנון מובנה במודל שפה הזאת, ועכשיו אני טיפ טיפה מקשר את זה למשימות שהן אולי רלוונטיות עבורנו. אז קצת להתחיל לקשר אותם לאזור של IR אולי, אבל עוד כמה שלבים בדרך. אז יש עוד תו מיוחד, ככה זה בברט, אבל יש את זה בכל מנגנון, תו מיוחד שממש אפשר להוסיף פיזית, כדי שאנחנו נקבל איזשהו OUTPUT כאן, שמופיע בברט לפחות בסוף המשפט.

אוקיי, זה ה-CLS הזה, ובעצם זה בשביל לאפשר למודל השפה לעשות פה קלוסיפיקציה. אוקיי, למה זה משמש? זה יכול לשמש אותנו לכמה דברים. בואו נגיד שאנחנו רוצים לחלק את המשפטים השונים שלנו לכל מיני מחלקות.

נגיד שזה יכול להיות למשל TOPIC. אוקיי, אנחנו רוצים לדעת מה הנושא, נגיד שיש לנו עשרה נושאים, ואז אולי באיזשהו מנוח היפוס, אנחנו מחפשים טקסטים שקשורים לנושא מסוים. אוקיי, אז מה שקורה כאן זה שכחלק מהסיקוונס, אנחנו כאילו מקשרים, עושים את זה על ידי סופר וייזלונה, אנחנו מקשרים בין המשפט הזה לבין הטופיק הזה.

וה-CLS כאן מסמן שהוא צריך, מסמן למודל שפה שהוא צריך פה בעצם לדחוף את הטופיק הרלוונטי, נגיד שזה משפט שמתעסק בספורט, אז הוא צריך בעצם שיהיה לנו פה World Embedding של ספורט. זה מה שהוא צריך ללמוד. אז בשביל לאפשר מנגנונים כאלו, בעצם מה שאפשרו בכל מודלי השפה הגדולים, זה באו חברות ענק, כמו OpenAI, כמו Google, או כמו Anthropic וכדומה, והם למדו מודלי שפה ענקיים.

לתהליך של הלימוד של המפלצת הזאת, בעצם אנחנו קוראים Pre-Training. כלומר, איזשהו שלב שאנחנו, הם יכולים לבזבז לפעמים חודשים על לימוד של מודל שפה שהוא מאוד מאוד יקר. חלק מהסיבה שהוא יקר זה בגלל אותם כפלי מטריצות שראינו קודם, אז בעצם ביחס לגודל הקונטקסט שלנו, המודל הוא ריבועי ביחס לגודל הקונטקסט, מאוד מאוד יקר, ורק מפלצות כאלה, כמו החברות הגדולות, יכולות ללמוד אותו.

אז הם לומדים איזשהו למידה מיוחדת, שיוצרת בעצם ייצוג של המילים על ידי הקונטקסט שלהם, על ידי משימה שבעצם הם בנו שתי משימות מרכזיות, משימה אחת זה תחזה לי תמיד מה המילה הבאה. Next Token Prediction, הם עשו את זה על ידי זה שהם כאילו בצורה חלקית מסתירים חלק מהמילים, ואז המודל צריך ללמוד מה המילה הבאה מסתברת ביותר. ועוד משימה נוספת של לימוד המשפט הבא, משימה מרכזית זה לימוד ה-Token הבא.

ובכל מקרה, אחרי שהם גמרו את המשימה הזאת שהייתה מאוד אפקטיבית, אפשר לקחת את ה-Pre-Trained Model הזה, ובמקום להתחיל עכשיו למידה מ-0 של בעיות שקשורות בשפה, אז אנחנו עושים מה שנקרא Fine-Tuning. מה זה אומר Fine-Tuning? אז דוגמה לזה אתם יכולים לראות למשל בצ'אט-GPT, צ'אט-GPT לוקח את מודל-GPT, ואתאים אותו לצ'אט-Bot, אז איך הוא עשה את זה? הוא לקח מודל שלקח הרבה זמן להימן, נגיד GPT-3, והוא יימן אותו כך שהוא יתאים ל-Do-Sieh בצ'אט-Bot, ואז מקבלים את הצ'אט-GPT על GPT עם תרסה מסוימת. אבל הלימוד והFine-Tuning הזה זה תהליך שהוא מותאם למשימה, והוא הרבה יותר קצר ביחס לחודשים אולי שנדרש ללמוד מודל שפה גדול.

אז זה הרעיון של Fine-Tuning, והקשר שלו ל-IR, שאולי נזכיר אותו גם בהמשך ונחזור על זה גם שבוע הבא, זה שעכשיו אנחנו רוצים לקחת מודל שהוא למד טוב-טוב את השפה האנגלית, ואנחנו רוצים להשתמש באותם אלה למים למשימות שקשורות ל-IR. אז יש לכם בראש משימות, בואו נזכיר רגע את השלבים שהיה לנו ב-IR הקלאסי, אז היה לנו את השלב של ה-Pre-Processing, והוא הוביל אותנו ל-Indexing, ויש לנו את ה-Query, יש לנו את ה-Ranking, ולפעמים יש לנו גם Query Expansion, ואפילו דיברנו על Re-Ranking. אוקיי, אז איך אנחנו רגילים נגיד, אם אנחנו חושבים על ה-Chatbot, אז בעצם יש לנו שאלתה, שמה שאנחנו עושים, אם אתם זוכרים למדנו Q&A, שאלות ותשובות, עושים את זה ברמה די ככה מאפנה, שאמרנו שאנחנו מתמקדים בעיקר בשאלות שרוצים לחלץ עובדות כלשהן, שאלות של נגיד, מה העיר הבירה של צרפת, אז שאנחנו מבינים שמדובר על Location, ועכשיו נחלץ את ה-Location שמדבר על עיר, ומופיע אולי בקונטקסט עם צרפת וכולי וכולי.

אוקיי, זה תהליך כזה בעיקר מבוסס חוקים, אולי בפנים יש הרבה למידת מכונה, אבל בעקרון התהליך מבוסס חוקים, ועכשיו ברמה עקרונית, מה שאנחנו רגילים לעשות עם איזשהו Chatbot נגיד, אוקיי, זה לשאול איזה, יש לנו פה רכיב של LLM, שהוא למד נגיד, הוא עבד על כל החומר שהיה באינטרנט הגלוי, את כל ויקיפדיה וכל המאמרים בכל מיני נושאים, ובכלל כמה שיותר מידע הוא למד, באמת כמות עצומה של מידע, ואז אנחנו שואלים אותו איזשהו שאלתה, והוא עונה לנו, כי הוא התאמן גם, עשינו לו Fine Tuning לנות בצורה של Chatbot, אוקיי, אז בעצם, מה שהוא עשה זה דבר כזה, אז ה-query שלנו היה בטקסט רגיל, אז הוא היה צריך להפוך את ה-query שלנו לאיזשהו סוג של Embedding, אוקיי, אז זה בעצם התפקיד הראשון של מה שהיינו צריכים לעשות, וצריך לפרק לראות איך אנחנו משתמשים בו בשביל זה. אוקיי, ואז הוא הבין בצורה כזאת או אחרת, מהמידע שיש לו בפנים, איזה מידע רלוונטי, הוא צריך להחזיר למשתמש ששאל לו אותה שאלה בצ'אטבוט. אוקיי, עכשיו, בהכירכם, אני לא יודע כמה זמן השתמשתם באיזשהו מודל AI ו-ZLLM, אבל איזה בעיות יש בתוכנית שעכשיו אנחנו שואלים, ומה ההבדלים בין זה לבין התהליך IR שאנחנו מכירים, בשיחה עם Chatbot.

כאילו, מה Chatbotים עושים שאנחנו שואלים אותם שאלה והם מחזירים לנו תשובה? אוקיי, במוד הרגיל שלהם, אני לא מדבר על המוד של ה-Deep או כל מיני כאלה, אז מה מיוחד, בעצם, מה מייחד את זה מהפלור של IR הרגיל שאנחנו שואלים, מקבלים מסמכים, איזה הבדלים יש בין זה, תכניסו גם את ה-Websearch אולי לתוך זה, מה ההבדלים בין זה לזה? אז אם אנו מודל, נגיד, ש-GPT-3 זה היה מודל up-to-date ל... נגיד, 2023, סתם אני ממציא, אז איזה בעיות יכולים להיות לנו? אז כמובן שאולי האיכות התוצאות בשאלת שאלות, אנחנו מקבלים תשובה, זה כבר שיפור לעומת מה שלנו ב-IR, זה לא מסמך, זה תשובה, יש בזה עדיפות, אנחנו לא רוצים בסוף דווקא את המסמכים, ולהתחיל לקרוא את הכל, היום במיוחד רגיל מקבל תשובות לאורסות, אנחנו רוצים את התשובה, אבל הבעיה היא שה-GPT-3, נגיד, הוא יתאמן על גרסה מסוימת של האינטרנט ב-2023 או ב-2024, ובעצם המידע שיש לו הוא לא עדכני, זה לא up-to-date. אז זו בעיה ראשונה שיש לנו כאן. בעיה שנייה שיש לנו כאן, זה שאין לנו בעצם, בואו נחשוב שאנחנו רוצים לעשות עבודה סמינריונית, לא יודע איזה קורס יש לנו עבודה סמינריונית, נגיד ב-Machine Learning, סתם אני מציעי, ואנחנו רוצים כחלק מהעבודה הסמינריונית, רוצים רפרנסים. 

אוקיי? אין לנו מקורות. ברגע שאנחנו שואלים אלה להם, הוא למד כל מיני קשרים, אבל מה הקשר בינם לבין מאמרים ספציפיים? מאיפה הוא הביא את המידע? אנחנו בסוף צריכים לצטט. אין לנו את המקורות המידע, אז זה נכון שהוא יחזיר פה תשובה כתובה וברורה, אבל מה עם המקורות של המידע שהוא נותן לנו? לפעמים אולי אנחנו רוצים כמה תשובות ואת הדירוג שלהם.

איך הוא עושה את כל הדברים האלו? אוקיי? ויש עוד בעיה נוספת שיכול להיות שהוא לא יודע את התשובה, והמודלים התאמנו לחזות את התשובה המסתברת ביותר, ולא התאמנו להגיד אני לא יודע. אוקיי? אז בעצם הבעיה השלישית זה שיש לנו נטייה גדולה אם סתם שואלים אל אלה ממלאה זיות, מה שנקרא hallucination וזיות, כלומר הוא ממציא את התשובה המסתברת ביותר גם אם זה שטויות גמורות. אוקיי? יודעים על כל מיני מקרים די הזויים שקרו בדברים האלו, ולכן מה שאנחנו נרצה ללמוד בפעם הבאה זה איך לשלב את הדבר הזה עם מידע עדכני בעזרת מנגנון שנקרא רג.

אוקיי? אז זה נדבר עליו קצת בפעם הבאה. רק נסיים כאן את הרעיון הזה. יש לנו כאן כמה גרסות של שיפור של ברט.

אני אדלג על זה הפער. ואיך קצת לעשות פרי-טרנינג, דיברנו על זה. שילוב של ברט ו- QA.

אוקיי, אז זה אחד מהשימושים שאמרנו, דיברנו עליו קודם בתרגום בין שפה לשפה. כאן זה בין אנגלית להינדית. אבל נראה לי שאני אסיים בשלב הזה ואני רוצה להגיד כמה מילים על העבודה הבאה. 

אני עוד אשלח על זמל, אבל לפחות שיופיעו כמה מילים גם בהקלטה. אז רגע, אני מפסיק את השיתוף. אז ברמה עקרונית זה יהיה כנראה בזוגות, שלשות, או לא יודע, צריך לחשוב על איזה גודל אנחנו מדברים עליו.

והרעיון הוא בסוף לבנות, לקחת את כל רכיבים שחלקם כמו הרג עוד לא למדנו, אבל אני פשוט לא רוצה לחכות עם ההסברים עד לשיעור הבא, כי זה יהיה רק עוד שבועיים. אני מבין ששבוע הבא אין שיעור, נכון? זה השבוע הבא זה חמישי הראשון, נכון? זה אמור להיות יום השלמה, אם אני לא טועה, של ימי חמישי. אמור להיות לכם שיעור ההשלמה של יום חמישי, אז לא אמור להיות שיעור בגלל זה.

אז אני לא רוצה לחכות עד עוד שבועיים, אז אני אגיד דבר כזה, אז זה כן אמור להיות יחסית פריסטייל, אבל זה אמור לכלול איזשהו רכיב מורכב במובן של, שיכלול גם רג, שיכלול גם קלטים מסוגים שונים, שימוש במודלים שהם מה שנקרא מולטי מודל, שהם גם נגיד אודיו וגם טקסט, גם תמונות וגם טקסט או משהו כזה, לבנות איזה מערכת סביב הדברים האלו, באיזשהו דומיינט שמעניין אתכם, ואני לא יודע אם אנחנו נספיק,