אז לפני הפסקה דיברנו קצת על מה זה נפשב טקסט בעצם, אוקיי? איך בעצם השפה מתחברת לנו מצד אחד, הטקסט מתחבר אלינו כסטרינג מצד שני, כמייצג שפה טבעית, אבל לא כל דבר שמייצג שפה טבעית נכנס פה בסנימה, דיברנו על כל מיני דברים שלו. אז מונחים שונים, יכול להיות שאתם שמעתם שקשורים לניתוח ואיבוד שפה טבעית, לפעמים זה נקרא טקסט אנלאסיסט, טקסט פרוססינג, שם היסטורי יותר, טקסט מיינינג, Natural Language Processing או פתרות NLP או איבוד שפות טבעיות בעברית. בואו נגיד שההיסטורית זה תחום שאשתיות לפחות היו שייכים לבלתנות חישובית, גם פה באוניברסיטת חיפה היו באסכולה של בלשנות חישובית, ולא ניכנס כרגע לניואנסים ביניהם, אבל אם אתם שומעים, כל הדברים האלה קשורים, אם אתם שומעים את הביטוי הזה, כל הדברים קשורים בעצם לדברים שאנחנו נדבר עליהם עכשיו.

אוקיי, אז כמה אתגרים שקשורים לבעייתיות וניתוח שפה? למה ניתוח שפה זה אתגר שהוא לא כל כך טריוויאלי? אז יש פה כמה אתגרים שבפרט רלוונטיים לענייננו בעיבוד שפה שקשור לחיסור מידע. דבר ראשון, יש לנו הרבה דרכים להגיד אותו דבר, אוקיי? אז זה יכול להיות ברמה הזאת של קיצורים אולי שנכתוב בטקסט מסייג'ינג אחד לשני, באפליקציות וואטסאפ וכדומה, שכל האפשרויות פה הן מתכוונות למחר, תמרו, או ברמה לעושר של השפה עצמה, אוקיי? יש לנו הרבה דרכים שבהם אנחנו לומדים את המידע שמישהו רכש משהו, נגיד, אוקיי? אז יכול להיות שזה משתמש במילה acquire או purchase, או בכלל יכול להיות שזה בצורה סבילה, she sold it to him, אוקיי? זה אתגרים שNLP מתעסק איתם כבר שנים רבות, ובעצם אם היינו מעוניינים לדעת איפה זה רכישה, אז סתם למצוא את הביטוי הזה לא היה מספיק לנו, משהו הופך לזה לאתגר הרבה יותר קשה. אז זה בעצם, נגיד, האתגר הראשון שאנחנו מזכירים, וריאביליות.

אתגר שני, כל מי שיצא לתרגם בין שפות, אז בטח מכיר בעצם את העניין הזה שהתכרגום בין שפות, קודם כל הוא לא ברמת המילה, אוקיי? אז צריך לדעת לתרגם לפחות ברמת הביטוי, ולפעמים אפילו ברמת המשפט, וגם אז יש דברים ששפות מסוימות, העושר שלהם, קשה מאוד לתרגם את זה, כי אין באמת ביטוי כזה בשפה אחרת, מה גם שלפעמים ביטויים יש להם יותר ממשמעות אחת. זה מה שנקרא ambiguity, אוקיי? יש לנו משהו שהוא רב משמעי, אוקיי? אז רב משמעי, מובנים שונים של רב משמעי, זה יכול להיות ברמת המילה, ויכול להיות ברמת הביטוי, וברמות אחרות. למשל פה יש לנו את המילה bank, שמין הסתם רובכם מכירים אותו במשמעות הכספית, אבל bank זה גם ערוץ נחת, אוקיי? איך נדע להבדיל ביניהם? בדרך כלל לפי הקשר, אוקיי? אז זה כבר דרך לפתור בעיות מהסוג הזה.

יש לנו, שוב, זה סתם עוד דוגמה אחת, יש המון דוגמאות ל-ambiguity, יש לנו כאן דוגמה של המילה slice, אוקיי? שיש לה משמעות שונה אם אנחנו מדברים על flies כפועל או flies כנר. אם flies כפועל, מכירים פה את הביטוי הזה גם בעברית, לא יודע אם יש לו מגדילה גם בערבית של הזמן רץ, אוקיי? ככה אומרים את זה בעברית, או זמן טס. והמילה fly זה גם דבוב, אוקיי? אז אם אנחנו רוצים להגיד ש... אוקיי, כאן יש גם רב משמעות למילה time, אוקיי? time is משהו, אוקיי? אז הזמן הוא משהו, אוקיי? כנראה שבמובן הזה לא מתכוונים שהזמן הוא דבוב, כנראה.

אם מישהו קצת מבין את ה... אבל אם אנחנו מנסים לתכנת מקשב שיתרגם את זה בטח אוטומטית, פעם מורכב יותר. אם נתייחס לכל מילה בפני עצמה, גם לtime וגם לflies יש שתי משמעויות. אוקיי, אז זה עוד מובן של ambiguity, וזה מובן קיצוני של ambiguity, הדוגמאות שיש כאן.

גם לאנשים לא ידעו לענות על הדבר הזה כמו שצריך, כן? אז זה אולי דומה למה שנקרא בדיחות קרש, או פעם היו קוראים לזה בדיחות אבא. אני יודע שהאבא של הבן או בת זוג רוצים להביך ומספרים בדיחות קרש, אז אם מישהו רחב על סוף ואזב, אז הוא פרש או לא, כן? כי אם את המילה פרש, להודות למישהו בפה מלא. כי אם את הביטוי להודות בפה מלא, כאילו מכל הלב, זה מנומס או לא? אוקיי? אם זה בפה מלא, זה לא מנומס.

אם הארכיאולוג פעילה חרס בידו, הוא הצליח או לא הצליח? טוב, זה צריך לקרוא. אם אני קורא את זה כבר בקול, אז זה כבר לא רע לשמור. אבל בעברית שאין ניקוד, גם בערבית בלי ניקוד אולי, יש למילים מסוימות שאפשר לקרוא אותם כמה.

אז אנחנו יכולים להגיד, באיסטנבול לא סוגרים דלתות, הם פורקים או הם טורקים. כן, אז אם קראנו את זה וערשנו את הערב משמעות, זה כבר לא רע לשמור. כן, תקלתי הרבה לפני שהחלטתי לעשות דיאטה.

אוקיי, זה גם ברור. טוב, זה מי שאוהב בדיחות קרף. אבל הקטע של לנתח את דבר כזה בצורה אוטומטית, בטח, אני לא יודע כמה זה אתגר בערבית שמילים עם ניקוד, אתם תגידו לי אולי, מי שדובר ערבית שוטף.

האם יש דוגמאות למילים שאם לא מנגדים אותם, אז יש להם רב משמעות גם, ומשהו שיש דוגמאות לא מעטות כאלה, שאפשר בלי הניקוד להבין איזה החרץ. בכמה מובנים, אני מניח שיש דברים כאלה, נכון? אני לא זוכר איך קוראים לסימני ניקוד, אני רק יודע לכתוב אותם. אבל המקביל החיריק וה... כן, לא זוכר.

המקביל החולם. וואו, זה למד. בכל מקרה, חוק זית זה גם עוד אתגר נוסף, שהוא ממש רלוונטי להחזור מידע.

מאוד מאוד ידוע. אם אנחנו לוקחים בדוגמה הזאת שיש כאן, נקחו ספר עם מיליוני מילים, אוקיי? וראו שמתוך ה-43 מיליון, אגב, אם מישהו פה יש לו קרובים מטורקיה, זה הכל בבדיחות, אף פעם לא... אני לא מישהו שיורד על אנשים, אז אל תיקחו את זה למקומות האלה. זה לא... לא אכפת לי כאילו לצחוק על דברים, אז אני לא אליב מישהו בכוונה.

43 מילים שונות יש בספר הזה, אבל מתוכם רק 316,000 מילים ייחודיות, שמתוכם יש לנו בערך חצי מהמילים שהופיעו רק פעם אחת, ואם אתם שמים לב, אנחנו יורדים כל פעם באיזה סדר גודל או משהו, ויש לנו 26,000 מילים שהופיעו יותר מ-50 פעמים, ואנחנו נמצא עוד רק עשרות מילים שהופיעו המון פעמים. אוקיי? זה הגרף שאנחנו רואים כאן. אנחנו רואים בעצם בציר ה-Y ה-unique type, כאילו מילים ייחודיות לצורך העניין, ומה שאנחנו רואים כאן זה את מספר המופעים.

אנחנו רואים שיש מילים שמופיעות מעט פעמים, הרבה פעמים, כשאנחנו מדברים כאן על מיליוני מילים. אוקיי? כשאנחנו מגלים על מיליוני מילים, כמה מילים ייחודיות בעצם יש. זה בעצם מה שהגרף הזה מראה.

הספר הזה קרא על 42 מיליון מילים, אז רק שסיימנו את הכל, אז הגענו ל-316,000 מילים. זה מה שרואים פה בדרך. בכל מקרה, זה אתגר גדול מאוד, כי לא כל מילה יש לה אותה משמעות.

ישנם רמות שונות בניתוח השפה מבחינת אתגר תישובי. עד עכשיו זה בעיות שהם, דיברנו עליהן, זה בכלל, לפני שהכנסנו את המחשב ככלי אוטומטי לעשות פרוססינג, זה היה עדיין מסובך. גם לבלשן שמנתח טקסט, רב משמעות יכול להיות אתגר.

אוקיי? תחשבו על מישהו שמתרגם ספר משפה לשפה, ואולי הסופר במקור הכניס בכוונה איזשהו משחק מילים כזה, מילה רבת משמעות, ואז כשמתרגמים את זה רק במשמעות אחד, אז זה קצת מאבד מהתרגום. מתרגם זה, לא יודע כמה יצא לכם לקרוא ספרות מתורגמת, אבל הרבה מאוד פעמים, האיכות יורדת בטח שאם זה מספר שהוא נקשר לספרות יפה. אוקיי, אז יש לנו רמות שונות של ניתוח של הטקסט של השפה.

פעם אחת בעצם כבר קצת דיברנו עליו, זה הרמה הפונולוגית. יש לנו פונמות בעצם, שלילים שאנחנו שומעים זה הפונמות. אנחנו רוצים לנתח את הטקסט, לחלק אותו לפונמות, ומכאן אפשר להפוך אותו למילים האלה.

כן, אבל זה אתגר שאולי נמצא הרבה פעמים, לא תמיד, רק בסיגנל שהמקור שלו היה בבויס. יש לנו אתגר של מורפולוגיה, שאנחנו נדבר עליו עוד מעט, אבל המורפולוגיה היא יחסית מחותכת בעברית וערבית. בשפות כמו אנגלית היא לא כל כך מחותכת.

יש לה מורפולוגיה יחסית פשוטה, ויש גם שפות אחרות שבהן מורפולוגיה היא סופר מורכבת. אנחנו נראה כמה דוגמאות לדברים האלה, אבל בכל מקרה, כאן אנחנו מדברים על חלוקה של משהו שאולי הוא ברמת המילה. אז קודם דיברנו על פונמות, עכשיו זה נקרא מורפמות.

מורפמות, בעצם כל מילה יש לה את הליבה שלה, עם המשמעות המילונית. שוב, עוד משהו, דיברנו קודם על ספרייה, שאני לא יודע כמה מכם מכירים באמת ספרייה פיזית, אז לא יודע כמה מכם מכירים מילון פיזי, אבל במילון יש לנו את הבסיס המילוני. כן, בעברית וערבית יש לנו שורש, אבל הבסיס המילוני נקרא למה.

זה הבסיס המינימלי של מילה במילון. שורש זה לא יופיע בתור הבסיס במילון, אבל למה כן. מה הדבר המינימלי שיש לו משמעות מילונית? זה הלמה, וכל השאר, מה שמחובר עליו זה המורפמות, והמורפמות גם יש להם איזשהו חלק דיבר.

אז אני מניח שכולכם למדתם בתיכון על נושא, סליחה, על שם עצם ועל פועל ועל תואר הפועל וכו'. אז כאן באנגלית זה noun, זה verb, זה adverb, adjective וכו'. אז בטח גם כולכם למדתם אנגלית ודקדוק.

וגם ברמה יותר גבוהה, עוד רגע אנחנו נדבר. אז כאן דיברנו על מורפולוגיה, זה דוגמה קיצונית. אז המורפולוגיה בעברית ובערבית באה לידי ביטוי באותיות ששמים בתחילת המילה ובסוף המילה.

אוקיי? אנחנו נראה דוגמה לזה עוד מעט. נגיד, אנחנו אומרים ילד ילדים. אז הצרועת רבים זה משהו שמוציפים בסוף.

אם אנחנו רוצים להגיד, היי ידיעה, היי ילד, זה בהתחלה. אוקיי? רוצים להגיד ווה וחיבור, הבאתי את הכדור ואת ה... לא יודע, המחצלת, אז זה ווה וחיבור בהתחלה. אוקיי? אז השפה הזאת, דוגמה מאוד קיצונית, שפה קשה יחסית מורפולוגית, יש גם אמצעיות.

אוקיי? לכל הדברים האלה קוראים affixes, שם כולל. מה שיש בהתחלת המילה זה prefixes, מה שיש בסוף המילה זה suffixes. ויש לנו גם את האמצעיות באמצע.

ובגרמנית אפשר להכניס גם עוד ועוד ועוד תוספות גם באמצע. כל הדבר הזה זה התרגום שלו לאנגלית. אני לא יודע אם מישהו מכם יודע גרמנית, אבל משמעות של המילה הארוכה הזאת זה התרגום לזה אנגלית.

אני אתרגם את זה לעברית גם life insurance company employee. עובד בחברה לביטוח חיים. אוקיי? זה המשמעות של המילה הזאת.

אוקיי? אז זו שפה עם מורפולוגיה, נגיד, מאוד מאוד מורכבת. ועוד רמה שהיום, יחד עם אל אלמים הזה, ברור לנו מאליו, אבל זה סופר מסובך. עוד לפני זה יש לנו תחביר.

כן? תחביר ברמת המשפט לבריאות. אז אם דיברנו קודם על סביל ופעיל, מישהו קנה משהו או המשהו נקנה על ידי מישהו, אז אם היינו יכולים לעשות ניתוח מדויק של התפקידים במשפט ולחלק את זה לכאן יש לנו noun phrase וverb phrase, המשפט עצמו זה ה-sentence נמצא למעלה, אז העץ הזה זה תוצר של ניתוח תחבירי, ולפעמים יש לנו גם פשטות בין הדברים האלה, זה דברים תוצרים מאוד מאוד מורכבים, ולפני העולם האל אלמים, בהתחלת עידן הקמשיטה יש לנו הרגוש שזה היה משימה חובה בשביל להגיע להבנה ממש של טקסט, אז זה התחביר, וכאן יש לנו גם את הסמנטיקה, את ההבנה, אוקיי? וגם פרויקט גדול כזה היה פעם של לנסות, אני לא יודע אם יצא לכם בתואר ללמוד פרולוג במקרה או לא, אין חובה, אוקיי? זה פרולוג זה שפה פרדיקטים כזאת, אז הכל מוגדר בצורה הזאת, אוקיי? אז אנחנו אומרים, יש לנו ישויות כאלה, X ו-Y, כך ש-X הוא כלב ו-Y הוא איש, ואז הגדרנו פעולה כזאת בין X ל-Y, אז זה פעולה שכל הדבר הזה מתאר שהכלב נשך את האיש, אז הדבר הזה אפשר בשפה לבטא אותו בכל מיני דרכים, אבל כאילו אם היינו יכולים להתארגן את זה למפה כזאת, זה המפה הסמנטית ההבנה של מה שאנחנו מתכוונים. אוקיי, אז זה רמות שונות של ניתוח שאנחנו כבר נדבר על חלק מהם עוד מעט, דיברנו קודם על קצת חזרה, בוא נגיד, אם התחזרנו קצת לצדדים, קצת חזרה להחזור מידע, אז אנחנו נדבר כאן על כל מיני נושאים, ונתחיל ברמות שונות של יחידות טקסט.

אז אנחנו מדברים על החזור מידע בעצם, בצורך העניין יש לכם במחשב אוסף של כל מיני משטחים שמעניין אותנו, או אולי בארגון יש לנו מתמטים שקשורים לאיזשהו תחום מסוים, שאני רוצה לחפש עליהם. אוקיי, אז הדבר הזה נקרא Collection, וספציפית בתחום של, גם במדעי הרוח זה נקרא ככה, של אוסף של מסנכים מתחום מסוים שמעניין אותנו לצורך משימה מסוימת, נקראת Corpus. אוקיי, במדעי המחשב אנחנו נפניש את ה-Corpus הזה לדייטסט, אם אתם מכירים את זה אולי מפורסים אחרים, את המושג דייטסט בטח.

Training set, test set, validation set, דברים כאלו, אז עוד לפני שהמציאו את המונחים האלו, האוסף הזה של מסנכים ושל דוגמאות, היינו קוראים לו Corpus, כאשר היחידה הבסיסית הגדולה, מבחינת גרנולריות, זה היה המסמך. אוקיי, היום מסמך לא חייב להיות באמת מסמך, אם זה, לא יודע מה, ניתן פה אחרי זה דוגמאות של איזה מחזה, שמשום מה אוהבים לתת אותן בתחום הזה של עיבוד שפה, אז יש לנו פה מסמך, אבל המסמך הזה יכול להיות גם, לצורך העניין, פוסט ברשת החברתית, שחבר'ה רוצים לעשות בעלי הסטטיסטיקה, או לפעמים אפילו הוא יהיה ממש משפט, אבל בוודאי הוא לא חייב להיות ממש איזה ספר כזה גדול. אוקיי, אבל לפעמים כן.

אם דיברנו על מסמך, זה יכול להיות איזשהו פרק, או פסקה, או משפט, או ביטוי, או מילה, או אפילו אות. אוקיי, כל הדברים האלה יכולים לעניין אותנו במובנים שונים, אז זה בעצם, ויש כמובן פה מיני, אולי אתם יכולים לחשוב על כל מיני יחידות בעיניים. פלג, פה באים כבר עם רקע של למידת מכונה, אנחנו מדברים על טקסט כאפליקציה למידת מכונה, אז יש לנו גם פה רמות שונות של משימות, שנרצה לעשות עם הרמות השונות של הטקסט.

למשל, לגבי מסמך, נרצה לזהות את השפה שלו אולי, אולי נרצה לזהות את הנושא או את הנושאים שלו, אולי נרצה לזהות מי כתב אותו, אולי נרצה לזהות את הסנטימנט שלו. כשאנחנו אומרים סנטימנט, אנחנו יכולים לחשוב על היום, בטח נתקלתם כולכם במערכות לא טובות של צ'אטבוטים, בטח לא יודע מה, לא רוצה להחליך על אף אחד, אבל ביותר בזיקופת חולים או ב... היום יותר ויותר, גם במערכות ממשלתיות אולי, תמיכה במוצר חשמלי ווטאבר, חולה מולכם ישר צ'אט, מה אני יכול לעזור, ואז הוא לא מבין כלום, ורוצים לכתוב שאנחנו לקוחות זוהמים, והיום פשוט שישראל עדיין לא שוק כל כך טוב של לקוחות, בניגוד לקומות אחרים בעולם, כאילו לא כל כך שמים על הלקוח פה בארץ נראה לי, מי שעובד בשירות לקוחות ויודע אחרת, אז אני מתנצל. מי זה הלקוח? כן, משהו כזה.

הלקוח תמיד מפריע. כן, בסדר. אז ברמה עקרונית, האינטרס שלנו בטח כשיש לנו תחרות אמיתית, בין שירותים שונים, זה שהלקוח יהיה מרוצה, כי אם הוא לא יהיה מרוצה הוא עלול, בואו נגיד שאנחנו לא אנשים טובים או משהו, יש לנו אינטרס כלכלי בלבד, אנחנו רוצים לזהות אם הוא כתב עלינו משהו, נגיד בפייסבוק, לא יודע כמה משתמשים בדרות לכם היום בפייסבוק, אבל כלי של עזקנים היום, נכון פייסבוק, מה היום הולך? איזה רשת חברתית, כן? אתה רוצים שאני, אני לא אעקוב אחריכם, סליחה, אין לי זמן לזה.

לא יודע, מה אינסטגרם או דרך כאלה? טוב, בסדר, אז אין הרבה מילים, אבל תחשבו שמתלוננים על משהו, כותבים איזה שורה ואני עכשיו מאוד כועס. מה? כן, אבל אין, אין צ'טבוט של, של מברסלת חיפה, נכון? אז כאילו, נגיד שהיה, אז הייתם רוצים לזהות, נגיד שסטודנטים פה יכולים לבחור, ללכת, אני לא יודע מה, לקריאה אקדמית אונו שראיתי, שיש לה פה קמפוס, או ללמוד פה. כאילו יש ממש מתחרים קרובים, ואם אתם עצבנים, אתם מהאוניברסיטת חיפה, עצבנים את הסטודנטים, אז תהיה נטישה, לא כדאי.

אוקיי, אז היינו רוצים לזהות את זה מוקדם, ולטפל בזה. אז זה, Sentiment Classification, זה המשימה הזאת, משימה, מהזקדן הצ'טבוטים, שהיא מאוד חשובה. אם אנחנו מדברים על גרנולרית יותר קטנה, כמו מקפץ, אפילו ברמה הזאת, זה הרבה פעמים דומה למשמח, אבל רק משימה הרבה יותר קשה, לזהות הנושא במשפט, או לזהות סנטימנט רק במשפט אחד, זה הרבה יותר קשה, אם יש לנו פסקה, או כמה עמודים וכדומה.

ברמת... רגע, דילגתי. ברמת המילה, אנחנו נדבר עוד מעט על מה זה Token. אבל ברמה העקרונית, יש לנו גם ביטויים, אבל גם ברמת המילים, אז אנחנו לוקחים בעצם, אכפת לנו מהו ה-type בשתי רמות.

קודם כל אכפת לנו, מהי המילה עצמה, כלומר, מה ה-label עצמו. יכול להיות שהמילה עצמה, נגיד, נכתבה בשביל ה-type, ובעצם אנחנו רוצים שקבוצה של כל מיני כתיבה, ייפשב לנו מילה אחת, ובוודאי רוצים לזהות את המילה, כן? ולנו אולי זה ברור מאליו, כל מי שכותב בשפות עם אלפרבט לטיני, עירילי, או עברי או ערבי, אז ההפרדה בין המילים בעיקרון היא ברורה, אבל כמו שנראה עוד רגע זה לא ברור. כן? אז נחשוב על מזרח הרפוק זה אפילו יותר.

אוקיי? אז נכון, אז לזהות את גבולות המשפט, את גבולות המילה, ובוודאי כל מיני דברים שכבר דיברנו עליהם, הקלק דיבר, מילה שמבטאת עצב או שמחה, אוקיי? זה משימות שונות, זה מעניין אותנו. אז מפינו פחות או יותר מילים שונות, ואפילו קצת עם משימות שונות, היה מעניין אותנו לבצע עליהן. אז נתחיל ממה שדיברנו עליו, על זיהוי של המילים, שלכאורה זה משהו מאוד מאוד ריבילי.

גם מי שלא יודע פייטון, אולי כאילו כולכם יודעים דאבה, או לא יודע, דאבה מכירים, לומדים בתואר? אוקיי, אז כולם יודעים מה זה string.split או משהו כזה, גם יש את זה, משהו דומה לזה בדאבה, וגם יש את זה בפייטון, אנחנו עושים split לפי רבע, אוקיי? אפשר לתת לכם דוגמה לזה, אם אתם צריכים ממחשה, אבל אנחנו נראה עוד רגע דוגמה לזה, ואז זה מסרק לנו את כל המילים, לתתי מילים, אבל אז אנחנו קצת מסתבכים. אז אפילו פה בטקסט הקצר שיש לנו כאן, אנחנו כבר מסתבכים, כי יש לנו פה סוגריים, אז הסוגריים הוא לא חלק מהמילה, נכון? אז בוא נגיד שאנחנו נפצל בין אותיות ללא אותיות, או אותיות במצפרים ללא אותיות במספרד. אוקיי, אנחנו נפריד ביניהם, וכל רצף של אותיות ומצפרים נחשיב כמילה, וגם את ההפרדות ביניהם, אולי כן, אולי שנתעלם מהם גם, לא יודע, נגיד, כאן אפשר להגיד שהמילים שלנו the sequence of characters, perhaps, letters, וכאן אולי המקף יאחד את זה מילה אחת, ואולי פשוט whitespace, כתמי מילים, לא משנה, בלי הסימני פיסוקים, נגיד, כי זה פחות חשוב אולי, למשימות מסוימות זה יכול להיות כן חשוב, אבל נגיד שאולי זה לא חשוב, אבל כמו שאנחנו נראה עוד מעט, הנה, זו דוגמה של מה היינו יכולים לעשות רק עם השמדה למילים, אז אם היינו מפרידים על ידי רווחים במשפט הזה, שזה משהו משייקספיר, איזשהו אחד המחזות שלו, שאני לא זוכר, friends, romans, countrymen, lend me your ears, גם דוגמה טובה למשמעות לא מילולית של ביטוי, אם אנחנו מסתכלים על רווח, כאילו, הסברנו איך היינו פותרים את זה תכנותית, אז זה לא מפריד מספיק כפר בין מילים, אז היינו לוקחים, נגיד, את כל התווים שהם לא תווים אלפנומריים, אותיות המספרים, ואז מפרידים ככה את המילים, אגב, כולכם למדתם ביטויים רגולריים? יודעים מה זה או לא כל כך? יצא לכם? אתם לומדים בתואר, חובה ללמוד פורס במודלים חישוביים, על אוטומטים ועל... מה? זה לא חובה.

טוב, נחליף קצת לדבר על regular expressions אולי, זה כדאי לדעת, גם אם עובדים כמתכניתים או כדברופס, כדאי לדעת, אז זה לא יזיק, אוקיי, אבל אתם יכולים לחשוב על איזשהו ביטוי שאומר, רצף של אותיות, כן, אפשר לתכנת את זה בצורה מאוד פשוטה, גם לא עם regular expressions, לבדוק האם זה... תו הזה הוא נמצא בין ASCII קוד הזה ל-ASCII קוד הזה, ואם כן זה אות. אוקיי? ואז הציק כמובן לא נופל בטווח הזה. כן, אתם... כולכם יודעים מה זה טבלת ASCII, אני מקווה, אוקיי, זה בעצם הכל נשמע כמספרים, זהו שלנו לקודת אותיות, ולשמור אותן בטבלה, וכל מספר מייצג אות.

אוקיי, אז... אז הנה דוגמה, אם היינו עושים חלוקה כזאת, היינו יכולים להפוך את זה ככה למילים. אוקיי, המשימה הזאת של לקחת טקסט ולחלק אותו במילים, נקראת tokenization, זה מסיבות כאלה ואחרות, וקצת נדבר עליהם, אבל לא יותר מדי לעומק, כי זה בכל זאת לא פרסנל פי, אנחנו ליקידה הבסיסית, ולא קוראים מילה אלא token. אנחנו לא כל כך מקפידים על זה, אבל... איבוד שפה הם יותר מקפידים על זה, אבל בכל מקרה, אם מדי פעם נגיד token, הכוונה מבחינתנו בדרך כלל היא למילה.

אוקיי, אז token, ולקחת טקסט ולחלק אותו לטוקן. אוקיי, זה לא טוקנים של פוקר, זה טוקנים במילים. בסדר? מה אתה אומר? אם רומן זה ער קטנה, זה ה-token שונה? אה... זה... בואו נתחת לזה עוד רגע.

כאילו, במקרה. אוקיי, כמובן, סתם לבוא ולהגיד, אנחנו לוקחים רק רצפים של... אז אם אלפן אומרים, זה משהו מאוד בעייתי. אוקיי, עכשיו תחשבו, אני יכול לכתוב פה את הקוד, אם זה עוזר לכם, כי הוא לא מקודדים, אז זה אולי... דווקא פה לתכנת את זה, מי שרוצה גם במגביל יכול לעשות את זה, לבוא ולקחת טקסט כזה ולפרק אותו רק לפי רצפים של אותיות, זה לא טוב.

אוקיי, אנחנו מדברים על טקסטים, שהם לאו דווקא בספרות שיקספירית, אלא יכולים להיות כל מיני דברים, אז כאן יש לנו דוגמה על אמוגי, דוגמה על... או אמוטיקון, סליחה, זה נקרא אמוטיקון, האמוגי זה הסמיילי ממש. לא חשוב. URL, כאן זה יוזר של טוויטר, אוקיי, אולי לא רק טוויטר, הטרודל הזה בהתחלה, ואז ה-username, אז בעצם, אם אנחנו נתייחס רק לרצפים של אותיות והמספרים, אז אנחנו נקבל משהו שלא אותו רצינו, אולי משהו שנראה ככה.

אוקיי, וזה כמובן לא הטוקנים שהיינו רוצים. אוקיי, היינו רוצים שהטרודל יהיה יחד עם ה-username, היינו רוצים שהנקודותיים והסגור סוגריים האלה יהיו ביחד גם, כי זה חלק מאותו מילה, כאילו, אותו טוקן, וגם בURL היינו רוצים להתייחס לזה כטוקן אחד, לכן המשימה הזאת שעל פניו נשמעה טריוויאלית, בטח בשפות שאליהם דיברנו, היא לא משימה קשה, אבל היא גם לא טריוויאלית. אוקיי, אז אם היינו יכולים, אם היינו עושים תרגיל, אז היה תרגיל לזה היום, אבל אולי שבוע הבא נראה.

אז זה ביחס לwhite spaces, אתם קצת מבינים שאפילו במערכת חוקים לא צריך איזה machine learning מורכב או משהו, כנראה אפשר לחסות את רוב המקרים עם כמה חוקים כאלו, עונים לנו על רוב המקרים. אוקיי, זה משהו שכן אפשר לעשות במערכת כזאת. קצת פטרנים ולענות על הפטרנים המרכזיים.

אוקיי, אז בשפות נוספות, בעצם השפות האלו, דיברנו קודם על כתב חרטומים, אבל יש עוד שפות שבהן כאן אנחנו כותבים מנדרינית, יפנית וצ'אי, שזו השפה שדוברים בטיילנד, גם בקוריאנית וככה. השפות האלו הם שפות שבעצם יש להן אלפי אותיות, חלק מהן גם משתתף את אותו אלפאבט, יפנית וצ'אינית זה צעירים שונים, אבל זה אותו אלפאבט, אחד קודם לאורח ואחד לאורך, לא זוכר אף פעם מה זה נח. אז בכל מקרה, שם המצב הרבה יותר מורכב, זו דוגמה כל מילה עצמה בעצם מורכבת לתתי מילים שנקראות הן זי או זי, ככה זה במנדרינית, והנה דוגמה לאיזשהו אתגר שהמשמעות שלו, אני לא ידע לקרוא מנדרינית, יאומינג reached the finals, הוא הגיע לתחרויות הגמר בצורך העניין, אבל אם נחלק את זה לא נכון, אז יש לנו פה כל מיני אפשרויות נוספות שנקבל אותן, והאתגר הזה הוא הרבה פעמים יהיה אתגר ממש של למידת מכונה, שתה מוסף של חוקים לא יספיק, אנחנו רוצים להתייחס להקונטקס, להתייחס לצביבה, למילים לפני למילים אחרי, ולהבין דרך זה, גם כנראה לא תמיד בצורה מושלמת, על התרגום או הפירוק הנכון, אז המשימה הזאת כבר לא נקראת tokenization, בשפות האלה נקראת סגמנטציה.

אולי נשמע קצת דומה לביטויים מתמטיים, שמחלקים את האזור הרציף לסגמנטים, אז אותו דבר כאן הרציף הזה של הוציאות מחלקים אותו לסגמנטים שמייצגים את היחידות של המילים. אוקיי, אז זה בעניין הזה. עוד משימה שיהיה לנו, שכבר הזכרנו אותה, זה בעצם נרמול של כל מיני מילים. 

אוקיי, אנחנו בסוף תחשבו, אנחנו בסוף רוצים לחטץ אולי את המילים האלו. ואם אנחנו מדברים על חיפוש, אז אנחנו גם נתייחס גם על חיפוש שהוא לא מדויק, אבל בדרך כלל, אנחנו רוצים למצוא סטרינג מדויק. אז בעצם, אם אנחנו מקבלים נגיד, משהו שהוא באנגלית נקרא אקרונים, לא בדיוק כושי תיבות, אבל דומה, אז רוצים ש-USA ו U.S.A או עם רווחים או כל מיני וריאנטים של זה, יהיה יקודת באותה דרך.

או צברה בעם, LTD, לא יהיה הבדל אם כתבנו עם נקודה פורמלי או בלי נקודה. אוקיי, אבל לדברים האלה, כמובן, יש כל מיני ריסקים. אם אנחנו מדברים על ה-US ועשינו עכשיו לאור קייס, כי בדרך כלל היינו זה לנוצר דברות לקטנות, והפכנו את ה-US ל-US זה אנחנו באנגלית, אז ועכשיו נחפש משהו ש... מצבי יחפש משהו שהוא התכוון אולי לארצות הברית והוא מצא את אנחנו, אז זה בעיה, זה כבר לא אותה משמעות.

איחדנו דברים שהם לא אותו דבר כ... איזשהו מילה אחת וזה אתגרים שצריך להתמודד איתם. דיברנו על זה שמילים מסוימות... אגב, גם כאן, זה סימן שאלה אם זה הרעיון טוב או דוגמה שיש פה. מי שמכיר פעם והיה החברת הרכב הגדולה בעולם, General Motors, היום אני כבר לא בטוח, מאז שנפנסו הרכבים החשמליים אז זה קצת הרבב את הכל, ובלי קשר קצת צאו הרבה מטפרים ו... יכול להיות שיש איזו משמעות לג'נרל מוטורס ולאור פייס, למרות שברצף הזה אני לא בטוח שזה כאן מאוד משנה.

בכל מקרה לחמים, דיברנו על שפות מורכבות מורפולוגיות, אפילו במורפולוגיה פשוטה בטח אנחנו נרצה להגיד שמילים בעלי אותה משמעות, גם אם פעם אחת אנחנו מדברים על לשון רבים או אזבחה או נקבה, אנחנו נרצה בעצם למצוא את אותם מילים בכל מקרה. אוקיי, אז אם אתם זוכרים, קודם דיברנו שהיחידה המילונית הקטנה ברמת המילה נקראת למה. אוקיי, אבל להוציא את הלמה מהמילה לפעמים זה קצת קשה אלגוריתמי.

אז פיתחו אלגוריתם חלופי שהוא עושה משהו דומה ללמה שהוא נקרא סטמינג. אוקיי, סטמינג בעצם מחפש איזשהו סטם שהרעיון שלו דומה ללמה, כן? סטם ונגיד הגזע, תרגום לעברית. אוקיי, אנחנו רואים אבל שבדוגמה פה נגיד הוא מאחד גם יותר מדי קצת, קצת גס מדי זה כל מיני וריאנטים של הסטמינג וכנראה לא מדויק אבל בסופו של דבר ביחזור מידע זה עובד בדרך כלל מספיק טוב. 

כאילו, מה הרעיון? פשוט אנחנו מורידים סיומות מסוימות אוקיי, שהרבה פעמים בתחום הסטטיסטית הם בעלי משמעות מסוימות. נגיד קריאיטינג, ה-IMG שמופיע בסורקס זה סיומת שבדרך כלל רלוונטית פשוט לאיזושהי צורה אחרת של פועל הסיומת של ה-IMG או ED לשון עבר או Created או Creativity. היינו רוצים להגיד ש-Creative ו-Creating יהיו ביחד. 

אז כאן זה הגיוני להוריד את ה-E ואת ה-IMG אוקיי, אז זו משימה ככה המשמע הזאת נקראת סטמינג הרבה פעמים עושים אותה גם להחזור מידע אגב, הכותרת של כל מה שאנחנו עומדים עכשיו עם סרג הדריל אוט כדי שלא תאבזו אותי אנחנו דיברנו על מה זה טקסט, למה אנחנו עושים את זה? כי בהחזור מידע אנחנו מחפשים את סמכים של טקסט. צריך לדעת מה זה טקסט אז דיברנו על זה. ועכשיו אנחנו מדברים קצת על פרוססינג של טקסט ברמה של המחשב איך בעצם, איזה מניפולציות, איזה עיבודים אנחנו רוצים לעשות על הטקסט כדי שבסוף אנחנו רוצים ש-Creative ו-Creating, שניהם ימצאו את המילה הזאת של נגיד, ליצור למרות שלא חיפשנו אותה בדיוק באותה דרך. 

אוקיי? אז אנחנו רוצים שנגיד מצמחים שמתחילים את המילה הזאת, ימצאו אותה למרות שהיא לא כתובה בדיוק כמו שחיפשנו אוקיי אז קצת להביצה המקומית שלנו זה קצת היסטורי, זה יחתנה קצת מאז. אז מה שאנחנו רואים פה זה בעברית וערבית קצת מקשים על המערכות הראשונות שהיו קיימות במחשב למה? כי מכמה סיבות? הסיבה המרכזית אולי זה שאנחנו כותבים מימין לשמאל ולא משמאל לימין. אוקיי? זה מאוד מסבך את המערכות מי שיצא לו להתעסק בסטרינגים בטוח לפעמים זה הודפס לפעמים הפוך או זה אוקיי? ו בוא נגיד זה קצת יותר עתיק מי שלמד שפצי אז מכיר את זה מראש מה לעשות? חלק מהמערכות שפיתחו אותם היו למטרה מסוימת כנראה צבאית במקרה הזה ואז הורחבו לכל העולם אז כשהמציאו את המחשב האישי אז פיתחו את הקוד האסקי מה היה בקוד האסקי עד 128 זה לאנגלית ועד 127, מ-128 עד 255 זה לשפות נוספות שהכל היה במקביל על אותו משטח אז הרבה פעמים נגיד בעברית היינו מטפיסים דברים ומקבלים את זה ביוונית כי עידוד לא היה נכון וזה נכתב אני מניח שכולכם מכירים ביוניקוד שכל השפות המדוברות שמופיעות במחשב יש להם ייצוג לאלפאבט שלהם שם אבל כשתווים הוצגו רק כדי בית אחד אז היה את הבעיות האלה אז זה היה משתמש גם שם אז גם היוניקוד וגם הכיוון זה היה האתגרים המרכזיים כמובן זה לא אלפאבט לטיני יש שם מוספות במשתמשות באלפאבט לטני שמאוד מקלות על כלים מסוימים לעבוד ואין את השיבושים האלה פתאום שאנחנו עוברים לכלי אחר לאיבוד כל הטקסט אז מה שעשו וזה היה אני מדבר לפני 20 שנה בערך בעברית ובערבית זה בשלב מאוד מאוד מוקדם של איבוד של הטקסט ועשו המראה לאלפאבט לטיני אז נגיד הערות חצת כמו בספרדית מי שמכיר תורגם ל-x איך אומרים ג'ורדו בספרדית? מכירים? אוקיי אז זה התרגום ב-x אני לא יודע כמה רואים בערבית אז אני אתייחס יש לנו, זה פשוט יש לנו אליפו הוא הופך ל-a יש לנו ג'ים שהופך ל-j אוקיי כדאי שאני אפסיק פה כדי שאני לא אפשרל כל עוד אני זוכר משהו בסדר אז זה היה השלב הראשון שעושים ואז אחרי שעושים את הדבר הזה, אז אפשר להשתמש באותה תשתית עכשיו הכל משמאל לימין, כל הכלים עובדים באותה דרך כמובן שרצף לאותיות מסוימות יכולות להגיד שם עצם או פועל ולא מפותח לפה לשפות, אבל הן את השיבושים שיש לאותיות שהן לא לטיניות או מימין לשמאל בעיקר, זה השיבוש המרכזי עד היום זה מפ שלא נפטר עד הסוף אבל בכלים המודרניים, שוב עברו ליוניקוב וכבר פחות משתמשים בזה, אבל פעם זה היה ה-common standard אוקיי, דוגמה ל-tokenization בעברית אוקיי, אזגרים דומים למה שראינו קודם באנגלית בטח גם תוכלו לחשוב על דברים אחרים בערבית אז יש לנו פה נגיד את התאריך שנחשב, עכשיו אולי קצת שונה פעם אחת, כאילו שפחות מקפידים על זה גם הראשי תיבות בעברית הן אחרים מאשר באנגלית פחות שימוש בנקודות בין אותיות, יותר גרשיים מתאחס לכם תובנות מגבילות בערבית יש לנו את הסימן שאלה שהוא הפוך מ... הסימן שאלה בעברית, נכון, אז כאילו אם לא יודעים את זה מראש אז לא מתייחסים לזה באותו דרך גם כאילו במשמעות להבין שזה משפט שאלה ולא... אז זה משהו שצריך להערך לזה מראש נגיד כאן, אם היינו עושים pre-processing ומנרמלים את כל הסימני שאלה, גם בצפרדית אגב, זה לא... אז היינו יודעים לטפל בתווים מיוחדים האלה אבל זה לא נגמר כאן, שכאן כמובן צריך להערך ל... די דומה מבחינת המשימות של אנגלית כאן יש לנו את ה... בעצם סיבוך בניתוח המילים בעברית בגלל המורפולוגיה המוכרת, אותו דבר בערבית אני לא מדבר ממש ערבית, אבל אם כאן כתוב ספרו ונגיד אני אומר בית הספר שלי, אז בטח תגידו שאני לא עוגב, זה נכון מדרסתי, אז כאילו, זה לא רב השמאלי אבל כאן זה רב השמאלי כי זה יכול להיות הם סיפרו, אין לנו ניקוז כך קוראים את זה, הם סיפרו, זה היכול באנגלית ספרו כאון, או אולי ספרו המילה ספרו אגב, מבחינה מורפולוגית זה ה-ספר-של-הוא אוקיי? באנגלית איתנו ה-הופך לזה כאילו גידוע, וספר זה המילה ספר בו חייכות זה גם מילה כן? אז זה של-הוא-וו בסוף אז המורפולוגיה פה היא מורכבת, בקיצור כדי שהמסר עבר ולנתח את הדבר הזה על המשמעות שלו אז גם לפעמים אנחנו נקפיד וככה אה, היה פה את הניתוח פה, גם אמרתי זה בעל פה אז המשימה הזאת שנקראת ניתוח מורפולוגי לפעמים יעניין אותנו רק החילות של הלמה זה נקרא למתיזציה ובעברית וערבית הלמתיזציה יותר חשובה כן זה שפות שהן קצת יותר מורכבות לניתוח של עיבוד שפה מאשר שפות כמו אנגלית שבהן לצורך יחזור מידע מספיק סתם אוקיי? שוב, כל זה בקונטקסט שבסוף נצטרך למצוא את המילים האלה או למצוא מילה עם אותה משמעות זה הסיבה שאנחנו נרצה לעשות דבר כזה אוקיי? הנה עוד קצת נרמולים בעברית, דיברנו על זה והריסקים שיש שם אם הפכנו את גברת לגב זה כמובן לא רעיון טוב זה מסוכן או דוקטור לדר כן, זה בעיה ואותו דבר יש טקסטים עדיין ששומרים את הניקוד ואני רוצה לקלף אותו בדרך כלל במיוחד בחיפוש, אף אחד לא כותב היום בניקוד לא בעברית ולא בערבית אז די פירטנו את כל המשימות עכשיו, קצת לחבר את זה לעולם תלחזור מידע אבל כל מה שדיברנו עליו עכשיו זה בעצם יהיה קצור למשימה של הכנה של טקסט להיחזור זה הסיבה שאנחנו מראים את המשימות האלו קצת לקונטקסט אוקיי? אז דיברנו על חלופה אנחנו מקבלים עכשיו מצמח טקסט לא משנה אם המצמח הזה היה טקסט ארוך או פוסט ברשת חברתית או מה שזה לא יהיה אנחנו רוצים לחלק את זה למשפטים, למילים אנחנו רוצים לעשות נרמולים שונים אנחנו רוצים אולי לחלץ חלקי דיבר אנחנו רוצים אולי לעשות ניתוח מורפולוגי או לפחות איזה סטמינג כזה אוקיי? אז כל הדברים האלו זה השלבים שאנחנו עושים עוד לפני שאנחנו שומרים את המידע יש לנו מסמך, רוצים לשמור אותו כדי שנוכל למצוא אחר כך וזה מה שאנחנו עושים אוקיי? אז מה שמקובל עד היום כנראה רובם משתמשים בזה וקודם היו פה שאלות ככה בין לבין על... זה מזכיר לנו קצת על האתגרים שדיברנו עליהם כבר ככה תזכורת אז נדלג את זה כי עשינו את זה רק עכשיו אז בעצם אנחנו מסתכלים עכשיו על טקסט ויכול להיות שאנחנו מחפשים משהו בואו נחשוב כרגע על רמת המילה אנחנו חושבים נגיד איזה מילה מסוימת המילה הזאת יכולה להופיע בהתחלה, באמצע, בסוף, משפט ראשון, משפט שני יחסית בסוף המסמך, יכולה להופיע בכל מיני מקומות אוקיי? עכשיו ההנחה המקלה שאנחנו עוסקים את הדבר הזה כדי שהוא יהיה בר חיפוש זה הנחה שהיא מאוד מקלה, אפשר להגיד שאין חשיבות לסדר מה זה אומר? לא אכפת לנו איפה המילה מופיעה אם זו מילה באמת מעניינת נדבר אולי קצת, לא יודע כמה נספיק היום אבל אפשר לדמיין את זה, אנחנו נדבר על זה יותר שבוע הבא אתה לחוף חוק זיף שיש מילים שמופיעות כל הזמן כל מיני מילות קישור כאלה למיניהם והם לא באמת, נגיד שאנחנו מחפשים איזה תוכן אז לצורך התוכן הזה הם לא באמת מוסיפות לנו הרבה מידע אוקיי? כמו מילים כמו את או אפילו מילים כמו אני או לא יודע אנחנו עכשיו רוצים לסמך בנושא מסוים ולא יעזור לנו להוציא עוד מידע אוקיי? אנחנו רוצים את המילים שיותר לא רוצה להגיד ייחודיות אבל יותר יש בהם תוכן אוקיי? אז אם המילה הזאת מופיעה זה ההיגיון של המודל הזה של bug avoid bug avoid כאילו יש לנו סקיות של מילים ולקחנו וזרקנו הכל לסקיות בלי חשיבות לסדר בגלל זה אז הפעם במישהו שכותב איזה מודל או אלגוריתם יש לו איזה דמיון ציורי בניגוד לאלגוריתמאים והמטליקאים היבשים בדרך כלל שאין להם עזר ואם זה עוזר זה מה שכנראה יעמד מאחורי זה אוקיי? אז זה המודל הבסיסי שאנחנו משתמשים פה עכשיו בפזור מידע דבר ראשון מוחקים את הסדר זה מוריד מאוד מאוד מהמימדיות בזה שמילה תופיע בדיוק במקום השלישי אחרי מילה מסוימת, לפני מילה מסוימת סיכוי שאנחנו נמצא תמה ברמה הזאת הוא מאוד מאוד נמוך אוקיי? אז הדרך שלנו להתמודד עם זה זה להגיד, קודם כל אין לך שירות לסדר אנחנו עושים מודל bug avoid אוקיי? דבר שני אז מה אנחנו עושים על המודל bug avoid הזה? אז דבר שני אנחנו רוצים להבין בעצם מה הם היחידות התנות ביותר שאנחנו רוצים לחפש אוקיי? אז זה יכול להיות המילה כמו שהייתה בדרך כלל כמו שראינו אפשר רמה מסוימת של processing בכל מקרה אם זה אנגלית אז בדרך כלל נהפכו את זה ל-lowercase אולי למעט יוצא דווקא אוקיי? לאותיות קטנות מי שלא מכיר את הביטוי lower ו-uppercase אוקיי? לפעמים אנחנו נעשה איזה תהליך של fly stemming או במקום המילה יופייה המילה המקוצרת או הלמה אוקיי? ולפעמים אנחנו נרצה איזשהו רצף של יותר ממילה אחת אוקיי? נגיד אנחנו רוצים לחפש גם את המילה עוד רגע נראה דוגמה שזה לא יהיה באוויר גם את המילה וגם את המילה שהופיעה אחריה אוקיי? גם את המילה וגם את שתי אלה שהופיעה אחריה אוקיי? לסוג הזה של הרצפים קוראים בעיבוד שפה n-grams אשר n אומר לנו את כמות המילים שברצף אם זה רצף של מילה אחת בלבד זה לא רצף זאת אומרת זה unigram רק בשביל השלמות רצף של 2 מילים בייגרם של 3 מילים טרייגרם של 4 גרם וכולי אוקיי? ולפעמים לפעמים למשימות קונקרטיות בכלל היחידה קטנה שלנו היא אות או ליתר דיוק בדרך כלל רצף של כמה אותיות משימה אחת שבאז עובד די טוב ובזיהוי שפה מסתבר שנגיד אפילו אם לוקחים שתי שפות עם אלפבט לטיני אז התפתחות של רצף של 3-4 אותיות באנגלית וצרפתית תהיה שונה אוקיי? אז לזהות בין אלפבט עברית אלפבט ערבית אלפבט קירילי ולטיני זה כבר יחלק אותנו לכמה אפשרויות ואז כדי להבדיל ביניהם מספיק בדרך כלל רצפים ברמת של כמה אותיות, לא מילה אוקיי? אז הגרנולריות לא תמיד תהיה ברמת המילה זה מה שנדבר להדגיש אז אנחנו בעצם מדברים על תהליך כזה שימו פרוססינג אנחנו יודעים עכשיו מה הם היחידות הבסיסיות לפעמים אנחנו שומרים כמה רצפים נגיד מילה, שתי מילים ושלוש מילים למשל, כן? בדרך כלל זה לא יהיה רק שלוש מילים זה יהיה מילה, שתי מילים ושלוש מילים שיהיה לנו כמה אפשרויות לשחק איתם ולפעמים זה מילה עם ברמת המילה עשינו את זה פרוססינג, אוקיי? ואת זה אנחנו נשמור זה הפרוססינג שאנחנו נעשה כיוון שאנחנו כבר מגיעים אז בעצם בתהליך הזה של bug of word דיברנו כבר על החלק הראשון מהו החלק הראשון? החלק הראשון זה שדיברנו על מה יהיו היחידות הבסיסיות שאותן אנחנו נשמור נגיד במסמך הזה יש את ההוספים האלו ברמת המילה או שני מילים וכדומה וזה מה שאנחנו שומרים לכל מסמך איך זה יראה? זה יראה משהו כזה אנחנו לוקחים פה איפה? רואים מאחורה? בערך? קצת קטן, אולי הייתי צריך להגדיל את זה המסמך שלנו כאן זה משפט, זה היחידת טקסט מה שאנחנו עושים זה חילכנו אותו למילים ואז כל מילה אנחנו ספרים כמה פעמים מופיע האמת שבשלב הראשון אפילו את זה אנחנו לא עושים עושים את זה בינארית, הופיע או לא הופיע אוקיי? עכשיו אנחנו עוברים, נגיד שיש לנו אלף מסמכים במחשב דיברנו קודם על איך להחזיר את המסמכים האלה מי שרוצה יכול לחשוב על מימוש של הדבר הזה למשל, יש לנו אלף מסמכים עוברים אליהם לפי הסדר אוקיי? אולי זה לא רק אידיאלי לבוא אליהם לפי הסדר, אבל עוברים אליהם לפי הסדר, כל פעם שיש לנו מילה חדשה שלא הופיעה קודם אוקיי? נוסיף אותה נמספר אותה כמילה הבאה בתור, יש לנו מספר סידורי רץ כולם פה יודעים מה זה השטייבל אוקיי, אז יש לנו את מבנה נתונים הבסיסי בטח בקורס מבנה נתונים או לפני זה למדתם את זה, מבנה נתונים הבסיסי של מערך, שבו פשוט שומרים את העברים לפי אינדקס לפי הסדר אוקיי? אבל עכשיו עדיין הם שמורים אולי לפי הסדר אוקיי? עדיין אנחנו רוצים לקודד אותם ככה אנחנו רוצים גם שיהיה לנו את הצד השני מה אנחנו עושים? מבנה הכי פשוט של key-value וה-table אנחנו מקודדים את זה לפי המילה וזה הוביל אותנו לאינדקס ששמענו את זה במערך אוקיי? אז אנחנו בודקים המילה הזאת נפיעה לנו בהשטייבל אם התשובה היא לא אז אנחנו עושים append למערך מקבלים אינדקס חדש אוקיי? נגיד המערך עד עכשיו מקום 10 ממקום 0 התפוס ועכשיו רואים שהמילה לא מופיעה בהשטייבל אוקיי? אז יודעים שצריך לעשות append למערך, להוסיף אותו באינדקס 10, ואז אומרים המילה הזאת בהשטייבל תצביע על 10 אוקיי? כך אנחנו כל פעם מוסיפים עוד מילים איך אנחנו מקודדים בסוף את את המסמך? אפשר לקודד אותו למשל ככה אפילו אמרתי בשלב הראשון לפני המספור פשוט 1 ו0 אם הוא מופיע זה 1 ואם הוא לא מופיע זה 0 אוקיי? משהו בוליאני כזה אוקיי? עכשיו המשמעות של האינדקס יהיה לנו מערך גדול מאוד מאוד מאוד שהוא מחזיק את כל המילים שמופיעים במסמכים במחשב נגיד אוקיי? ואז מסמך ספציפי נגיד המסמך הזה כאן קצר מאוד רק משפט יהיה לנו וקטור מאוד שרוב והוא יהיה 0 אוקיי? אבל מדי פעם יהיה 1 אם ככה ואז כשאנחנו נעשה חיפוש בהמשך אני קצת קופט כמה שלבים קדימה אז פשוט נראה אם באינדקס 5 יש לנו 1 או 0 ככה נראה אם המסמך הזה מכיל את המילה או לא אוקיי? זה רעיון ושם אנחנו חופרים להגיע בכל מקרה ייצוב סתם אני לא יודע אם גם מי שאין לו רקע בלמידת מכונה וכאלה אולי בקורס מתמטיקה אתם מכירים את התצוגה המתמטית הוקטורית הזאת אוקיי? יש לנו מי שלמד בתיכון פיזיקה אז יש תצוגה גיאומטרית של גודל נורמה וזווית אז זאת תצוגה פיזיקלית גיאומטרית בתצוגה אלגברית הוקטורים נראים ככה בעצם כל נקודה במרחב שבו על המישור שלמדתם על דוסת המישור כל נקודה במרחב רגע אני אצייר לכם את זה אולי אני מקווה שתראו את זה אז עובד במקור זה מאוד פל להסביר את זה יש לנו פה רואים שם אחורה? אוקיי אז יש לנו פה שני צירים יש לנו פה נקודה נגיד הנקודה הזאת היא נגיד שלוש שלוש ציק ארבע אז בעצם אם אנחנו מבינים ש וקטור זה גודל וכיוון אוקיי? אז אנחנו יכולים למתוח מפה בעצם ישר לראשית הצירים ואז הזווית בין ציר ה-x לבין הישר הזה זה הזווית שלנו והגודל בין נקודה 0,0 לנקודה 3,4 זה בעצם הנורמה של הוקטור אז ככה קיבלנו תרגום מתצוגה אלגברית של וקטור לתצוגה גיאומטרית אוקיי? הבנו את הפרנספורמציה הזאת? אולי אתם מכירים את זה כבר אני לא יודע אבל אם לא אז עכשיו אתם מכירים במישור הכי קל להראות את זה כמובן אז בעצם גם הדברים האלו כאן בצד שחלק מהם יצאו בפרונקים שונים בטעות משום מה אז גם אלו הם וקטורים וקטורים במרחב מה מימדיות של הוקטורים? מימדיות כמספר המילים בבוקאבלרי שלה אוקיי? זה יכול להיות די הרבה אבל עדיין אנחנו מדברים על מחשב האישי אז אפשר להציג את זה בצורה כזאת בדרך כלל אוקיי? אז בדרך כלל אז ככה יכולים לראות הייצוג של המסמכים השונים אוקיי? ו... רגע נילגתי אז דיברנו קודם על יש לנו עוד קצת זמן עכשיו זה עדיין לא סיימנו אז דיברנו גם על אינגרמים אוקיי? אז אנחנו רואים בכחול בשורה הראשונה בעצם חלוקה של הטקסט כאן כתוב פה זה Special Onion Soup Was Not Very Bad המערק בצל מיוחד לא היה כל כך נורא אז כאן במשפט הראשון החילה כמו זה למילים במשפט השני למילים אנחנו קוראים לזה Unigrown אוקיי? זהו הילה אחת Special Onion Soup וכו' אוקיי? כאן זה מונח שכדאי שתכירו בלי קשר גם נגיד אם מעניין אתכם עיבוד תמונה וחלון גלאז אפשר לכם להכיר את זה אבל גם באלגוריתמיקה לפעמים מלמדים את זה אז מה יש לנו כאן? אינדקס התחלה וגודל אינדקס התחלה בהתחלה זה המילה הראשונה ואז הגודל הוא שתיים אז אנחנו לוקחים זהו Special שתי מילים זה ByGram עברנו למילה הבאה אינדקס הראשון שם זה מילה מספר אחד נגיד, מתחלנו מהפס Special Onion אנחנו לא קופצים בשתיים לפי גודל החלון אלא כל פעם קופצים מילה וגודל החלון נשאר אותו דבר ככה אנחנו שומרים את את הבייגרמים שלנו ואותו רעיון ב-N גדול משתיים של N גרמים אוקיי יש לנו עד ארבע וחצי, נכון? טוב אז להתחיל לבוא פשוט על פייטון נראה לי אין לנו זמן עכשיו אני פשוט מראש בניתי את זה בצורה כזאת שכספחות חלק מהמצגת הבאה תמופיע גם במודל נתחיל אז פשוט אני חושב שזה יעזור לנו גם מבחינת הקונטקסט אוקיי אז יש לנו גם איזשהו סיכום קצר קצר ככה של מה שלמדנו עד עכשיו זה מה שאוהבים לקרוא לו recap summary כזה, סיכום אוקיי אז דיברנו על מה נכנס לנו לטקסט כstring דברים גם שהם לא בדיוק stringים דיברנו על מורכבויות של השפה באופן כללי עוד לפני ההגעה לעיבוד שפה באופן אוטומטי אוקיי על אתגרים כמו החוק זיף ודיברנו על כל מיני משימות כמו ניתוח פרופולוגי ולמטיזציה על stemming על נרמול של המילים שאנחנו עושים כל הדברים האלו זה הפרי-פרוססינג שאנחנו עושים על הטקסט החלנו לדבר בעצם על המודל של בגה ורוב שאומר מיקום שלנו בתוך הטקסט לא חשוב כמובן שאם אנחנו שומרים בייגרם אז קצת שמרנו על רצס אמנם אבל עדיין הרצס הזה יכול להיות הרצס הזה הוא היחידה אטומית שלנו הוא עדיין אבל יכול להיות בתחילת המסמך באמצע המסמך, בסוף המסמך אוקיי אז הצלע השנייה כמו שכבר התחלנו להגיד זה צלע איך לקודד את כל הדבר הזה אוקיי, אז מה אמרנו שיש לנו כאן אמרנו ולצורך העניין כרגע אנחנו שומרים את זה ככה יש לנו כאן מבנה נתונים שהוא מורכב מאיזשהו מערך גדול וכאן יש לנו את כל המילים שנגיד מופיעות בטקסט נגיד שכאן המילה הראשונה הייתה זו לא יודע מה כתוב פה אה אין פה דוגמה לא חשוב ניקח את הדוגמה הקודמת זה onion, soup אוקיי וזה אינדקסים שלנו 0, 1, 2 וכאן יש לנו איזשהו השמאפ שכתוב לנו פה שזר מצביע ל-0 אניין מצביע ל-1 וכן הלאה בסדר? אז זה בעצם הדרך שבה אנחנו כרגע כבר לא הזכרנו את המילה לאינדקס אבל זה כבר אינדוק אוקיי כל התהליך הזה של הפרוצסינג של השמירה שלו בעברת מערך אחד, השטבר אחד זה כבר אינדוק של המידה זה עדיין לא הצורה שבה שיש לנו הרבה מידה אנחנו נאינדקס, כבר נגיע לזה אולי אפילו מספיק עוד מעט אוקיי אז דיברנו גם על כל מיני פרוצסינג אמרנו האלו ברגע דיברנו על זה אז אני מדלג, אז הנה דוגמה שיש לנו כאן יש לנו איזשהו שאילתה שהשאילתה הזאת היא בעצם המודל החזור הראשון שלנו כולכם אני מניח גם אם לא למדתם ממש קורס ולוגיקה בטוח למדתם בתכנות איך להתעסק עם ביטויים בוליאניים עם הביטויים של האן ושל האור ושל הנות כל הדברים בטוח כולם מכירים אוקיי אז לצורך העניין המודל החזור הבוליאני המודל הקלאסי הראשון אוקיי זה פשוט בא ומבקש לנו תן לנו עכשיו זה מחזות של שייקס פרשון לא יודע כמה פה אנחנו שולטים במטריה אבל יש לנו פה הוא מכיל את ברוטוס וגם מכיל את סיזר, קיסר אבל לא את חלפו שאני לא מתמחה בזה אני אפילו מצליח לגלגל את זה ללשון נתקלת, יצא לי ככה אוקיי אז זה ממש ביטויים בוליאניים אז מה אנחנו עושים יש לנו את כל המילים אוקיי שאנחנו שמרנו בצורה הזאת וקודמנו את הכל מופיע לא מופיע, אחדים ואפסים יש לנו וקטורים שמייצגים כל מסמך אוקיי אז יש לנו כרגע שלושה מבנה נתונים בעיקרון, מבנה נתונים אחד מערך גדול מבנה נתונים שני מבנה נתונים שלישית לייצוג מסמך אחד כל מסמך הוא בעצם וקטור ייצוג של כל הקולקשן או הקורפוס שלנו אז זה מערך של, זה מטריצה כן, מטריצה של לצורך העניין ציר הוואי שלה זה המקום בציר הוואי המימד בציר הוואי זה מספר המילה המימד בציר האיקס זה מספר מסמך אוקיי ואז עכשיו יש לנו איזה שהיא שאילתה אוקיי מכירים כולם לצורך העניין ביטקוויז Operations אוקיי אז בחשבון גוליאני, אוקיי ממש אפשר לעשות דבר כזה אוקיי נגיד שיש לנו מסמך אחד בוא נגיד כרגע, נעשה תרגיל קל, נגיד כרגע שהיה לנו רק 32 מילים בקורפוס שלנו מה היינו יכולים לעשות אגב יצא לי להשתמש במשהו כזה במקום עבודה אז כאילו זה לא סתם, היינו יכולים להציג את המילים שלנו בצורה כזאת של אפסים ואחדים אוקיי ואז אנחנו עושים ביטקוויז Operations שזה O של 1 לצורך העניין אם אתם בוחרים את המונחים האלה עוד, כן זה פעולה אטומית אחת של מחשב אוקיי ואז יש לי עוד מסמך אחר שמופיע בו 1 0 0 1 ועוד מסמך שלישי שמופיע בו נגיד נתנו שזה לא תוריד כלום רגע 0 1 0 1 אוקיי נגיד שכרגע אני מחפש את כל הביטויים נגיד שאני מחפש משהו כזה 0 1 0 0 1 0 0 אוקיי אז אנחנו בעצם צריכים לקחת את הביטוי של השאילתה לעשות AND על כל המסמכים שלנו ובעצם נקבל כל התשובות שהן לא 0 כן עושים AND לוגי נגיד עושים AND לזה ולזה 0 1 0 0 יחד עם 0 1 1 0 אוקיי אז 0 1 0 0 נגיד שהיה לנו אור בין המילים אוקיי נגיד שכאן אפילו היה לנו את הדבר הזה אבל היה לנו במקום AND היה לנו אור בין המילים מופיע בזה או קיסר או ברוטוס נגיד אוקיי אז אם היינו לוקחים עכשיו אמנם נגיד ברוטוס זה המילה הרבית לא הופיע אבל קיסר כן הופיע ולכן בגלל שזה הפעילות אז מספיק שה AND בין שתי המסמכים האלה ייתן לנו משהו שהוא שונה מ0 ומצאנו תוצאה אוקיי אז כך הפעם שהיה לנו דברים מאוד מאוד קטנים לא היה לנו פורפוס גדול, מעט מסמכים מעט ביטויים, כך היינו יכולים למצוא, אוקיי היינו מהנדקסים את זה בצורה מאוד פשוטה, אפילו אולי INT אחד היה מספיק, אני קצת מגזים אבל בצורך התהליך שעברנו זה היה השלב הראשון אוקיי עכשיו אוקיי אוקיי היינו עושים דבר כזה נראה בצורה הזאת כמו שעשינו מקבלים משהו כזה לצורך העניין מה שיכול להיות כאן זה יכול להיות גם משהו שמייצג מסמכים וכן הלאה אוקיי הדבר הזה הוא כמובן לא סקלבילי, מכירים את הביטוי זה לא סקלבילי? לצעריכם אני מבין כן זה היה נדמה מיואש ממש אוקיי אז אה בסדר זה כמו שכל חברה חייבת שיהיה להרכיב AI היום, זה אותו דבר אוקיי אז מה עשו בשביל שהדבר הזה באמת תהיה אפשר לייצג אותו בצורה סבירה שהיא אה לא הופכת על הדבר הזה מפלצת כבר לא כל כך זולה, היא קרה מדי אוקיי, מה הרעיון בכלל להסתמת בעת קבל הייתי צריך להגיד את זה ואולי לא ברור מאליו, אם יש לנו מערך שאנחנו שומרים בו אה פשוט את כל המילים שיש בקובץ אז עכשיו, הירקנו את זה כבר למילים אין חשיבות לסדר, יש לנו ככה הנה המילים הייחודיות שיש במסמך אוקיי, אז עכשיו החשיבות שהם הולכים לעבור על כל המילים לראות אם המסמך הזה מכיל את המילים זה יקר מאוד לעבוד עם השטאבל זה כבר מאוד מעיץ את הביטוי את הביצועים אוקיי, השלב הבא שאנחנו רוצים לעשות זה לעשות משהו שאנחנו קוראים לו בהחזור מידע, זה בעצם השיטה או אולי המבנה נתונים שעד היום עובדים איתו זה נקרא inverted index זה דומה מאוד לרעיון של השטאבל מה הרעיון? אנחנו לוקחים את כל היגידות הבסיסיות, לנו נגיד מילים אוקיי, ודרך המילה מדבים על כל המסמכים שמכילים אותם אוקיי, גם פה יש כל מיני אופטימיזציות שאפשר לעשות במיון הפנימי תקחת אולי את המילים היותר חשובות, היותר שכיחות כדי שיהיה פחות זמן למצוא בכלל את המילה, לא יודע יש כל מיני אופטימיזציות שם או את המסמכים שיש סיכוי יותר גבוה שנמצא, אוקיי אז יש לנו פה ברמה עקרונית אפשר להגיד איזשהו השטאבל אולי שמצביע על linked list אוקיי, linked list של ID של מסמכים אוקיי, ו הדיקשנרי השטאבל מצביע על הפוסטינג זה אלה, ככה קוראים לlinked list הזה שההגיון הוא אוקיי אם המבנה הזה בוא נגיד, מקרה קל היה מערך בגודל קבוע, היינו עושים חיפוש וינארי ומוצאים האם ה-ID שלנו נמצא שם כן או לא, ככה יודעים שהמסמך הזה נמצא, מכיל גם את המילה הזאת וגם את המילה הזאת שהחיפוש הבוליאני דרש אוקיי, אז הבעיה היא שכל הזמן נוסיף עוד ועוד מסמכים, הדבר הזה יהיה מאוד קשה לתחזוקה, צריך למיין אותו כל הזמן אוקיי, כדי שיהיה קל שוב למצוא את ה-ID של המסמכים, לדעת אם מכילים את המילה הזאת או לא אוקיי, אז לא יודע, יכול להיות שנספיק שבוע הבא לדבר על מבנה נתונים לא יודע אם למדתם איזה ביקור של מבנה נתונים, אבל יש מבנה נתונים שנקרא skip list שמקובל מילים שלא אז אולי נזכיר אותו אז זה כרגע מה שה הפלור שיש לנו, אנחנו כבר מסיימים אוקיי, עוד דקה שתיים אז כרגע תנראה ככה, יש לנו מצד אחד מסמכים כמו המשפט הקצר הזה, נגיד שהוא מסמך עשינו טוקניזציה אולי עשינו כל מיני מניפולציות על המילה כאן פשוט הפכנו אותיות קטנות לאורקייס אוקיי, ובשלב הבא עשינו אינדוקס כן, המילים האלו באיזה מסמכים מופיעים זה האינברטד אינדקס שלנו אוקיי, ו אנחנו לוקחים את המצלצת הארוכה הזאת כן, אז זה מכיל כאן את כל הביטויים ודבר ראשון אנחנו ממיינים מעבר מצמו לימין, ממיינים לפי הטוקן אלפבטית שוב, כדי שאפשר למצוא מהר את המילים ובשלב הבא נדילגתי אוקיי, אנחנו עושים עוד התייחסות גם לכמות או אפילו איזה מיון משני לפי כמות המופעים של הביטוי וכמה מסמכים מופיעים, זה מה שנקרא Document Frequency אוקיי אז זה המבנה הבסיסי ש... זהו, גמרנו עלו עלינו טוב, כל אחד יודע מאיפה הוא אמור לברוח אז נמשיך מהמקום הזה שבוע הבא אוקיי לפני הפסקה דיברנו קצת על מה זה נפשב טקסט בעצם אוקיי איך בעצם השפה מתחברת לנו מצד אחד הטקסט מתחבר אלינו כסטרינג מצד שני כמייצג